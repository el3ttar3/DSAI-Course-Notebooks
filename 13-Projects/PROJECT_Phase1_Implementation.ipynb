{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Wp3yHjuAzNUK"},"source":["# Phase 1 — Nature Inspired Computation Project\n","\n","**Dataset:** ISIC (dermoscopic skin lesion images) — clinical, high-dimensional, >20k samples.\n","\n","Notebook Content: dataset import, baseline model, feature extraction, Ant Colony feature selection, and four metaheuristic hyperparameter optimization methods (PSO, GA, DE, SA)"],"id":"Wp3yHjuAzNUK"},{"cell_type":"markdown","metadata":{"id":"1lyLrC8-zNUM"},"source":["## 1) Setup — install dependencies\n","install packages used for metaheuristics."],"id":"1lyLrC8-zNUM"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jVUL1NRzNUN","executionInfo":{"status":"ok","timestamp":1762343994608,"user_tz":-120,"elapsed":21375,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"}},"outputId":"48d3086e-ae11-4e40-fcbb-e13c6d2fb823"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/136.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hSetup done. TensorFlow version: 2.19.0\n"]}],"source":["# Install required packages\n","import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","try:\n","    import tensorflow as tf\n","except Exception:\n","    !pip install --quiet tensorflow\n","    import tensorflow as tf\n","try:\n","    import pyswarms\n","except Exception:\n","    !pip install --quiet pyswarms deap\n","    import pyswarms\n","import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","print('Setup done. TensorFlow version:', tf.__version__)"],"id":"7jVUL1NRzNUN"},{"cell_type":"markdown","metadata":{"id":"IbfDZSQ5zNUO"},"source":["## 2) Dataset: download & load\n","\n","Two options: (A) **Kaggle** ISIC mirror or (B) **HuggingFace** processed dataset. If you have a Kaggle token, use Kaggle; otherwise download manually and upload to runtime. Below are example commands for Kaggle."],"id":"IbfDZSQ5zNUO"},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Path where your Kaggle token is currently located\n","kaggle_json_src = \"/content/kaggle.json\"\n","kaggle_json_dst = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(os.path.dirname(kaggle_json_dst), exist_ok=True)\n","\n","# Copy the file to the default location\n","shutil.copyfile(kaggle_json_src, kaggle_json_dst)\n","\n","# Fix permissions (required by Kaggle API)\n","os.chmod(kaggle_json_dst, 0o600)\n","\n","print(\"✅ Kaggle token copied to:\", kaggle_json_dst)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEL7oacs21Es","executionInfo":{"status":"ok","timestamp":1762344014367,"user_tz":-120,"elapsed":25,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"}},"outputId":"86e5cf48-7d13-4ccd-e6e3-7ec43ef1b431"},"id":"KEL7oacs21Es","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Kaggle token copied to: /root/.kaggle/kaggle.json\n"]}]},{"cell_type":"code","source":["import os, shutil\n","\n","# your existing token\n","src = \"/content/kaggle.json\"\n","\n","# both possible destinations\n","dst1 = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n","dst2 = os.path.expanduser(\"~/.config/kaggle/kaggle.json\")\n","\n","# create both directories\n","os.makedirs(os.path.dirname(dst1), exist_ok=True)\n","os.makedirs(os.path.dirname(dst2), exist_ok=True)\n","\n","# copy to both (safe redundancy)\n","shutil.copyfile(src, dst1)\n","shutil.copyfile(src, dst2)\n","\n","# fix permissions (required)\n","os.chmod(dst1, 0o600)\n","os.chmod(dst2, 0o600)\n","\n","print(\"✅ Copied kaggle.json to both expected paths:\")\n","print(\" -\", dst1)\n","print(\" -\", dst2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hslKg67I3Qhr","executionInfo":{"status":"ok","timestamp":1762344023592,"user_tz":-120,"elapsed":724,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"}},"outputId":"3967b72e-a7d0-43ee-c922-53b72d3ba28f"},"id":"hslKg67I3Qhr","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Copied kaggle.json to both expected paths:\n"," - /root/.kaggle/kaggle.json\n"," - /root/.config/kaggle/kaggle.json\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dejLd2ZKzNUP","outputId":"583df70b-b8b8-4f55-daa1-ba193aab8ec0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/salviohexia/isic-2019-skin-lesion-images-for-classification\n"]}],"source":["from kaggle.api.kaggle_api_extended import KaggleApi\n","api = KaggleApi()\n","api.authenticate()\n","\n","DATA_DIR = '/content/data'\n","os.makedirs(DATA_DIR, exist_ok=True)\n","\n","api.dataset_download_files(\n","    \"salviohexia/isic-2019-skin-lesion-images-for-classification\",\n","    path=DATA_DIR,\n","    unzip=True\n",")\n","print(\"✅ Download complete — files extracted to\", DATA_DIR)\n"],"id":"dejLd2ZKzNUP"},{"cell_type":"markdown","metadata":{"id":"bk7mfoB-zNUP"},"source":["## 3) Preprocessing & Data generator\n","We use Keras `image_dataset_from_directory` if images are arranged in class folders. Otherwise load CSV mapping image->label and build TensorFlow dataset."],"id":"bk7mfoB-zNUP"},{"cell_type":"code","metadata":{"id":"wMCOqi_hzNUP"},"execution_count":null,"outputs":[],"source":["import tensorflow as tf\n","import tensorflow.keras\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","\n","# Example: if you extracted HAM10000 into DATA_DIR/ham10000\n","IMAGE_SIZE = (224,224)\n","BATCH_SIZE = 32\n","\n","# If your images are arranged in subfolders per class use this (uncomment and set path):\n","# train_ds = image_dataset_from_directory(os.path.join(DATA_DIR,'train'), image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, shuffle=True, seed=123)\n","# val_ds = image_dataset_from_directory(os.path.join(DATA_DIR,'val'), image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\n","\n","print('Define data loader according to your local filesystem. If using ISIC CSV, load the CSV and build tf.data.Dataset mapping filenames to labels.')"],"id":"wMCOqi_hzNUP"},{"cell_type":"markdown","metadata":{"id":"z73hNGcbzNUQ"},"source":["## 4) Baseline model (transfer learning)\n","We build an EfficientNetB0-based classifier with a small dense head. This is our baseline before metaheuristic tuning."],"id":"z73hNGcbzNUQ"},{"cell_type":"code","metadata":{"id":"0x_T_6DezNUQ"},"execution_count":null,"outputs":[],"source":["from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras import layers, models, optimizers\n","\n","def build_baseline_model(num_classes, input_shape=(224,224,3), dropout=0.3, lr=1e-4):\n","    base = EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')\n","    base.trainable = False\n","    x = layers.GlobalAveragePooling2D()(base.output)\n","    x = layers.Dropout(dropout)(x)\n","    out = layers.Dense(num_classes, activation='softmax')(x)\n","    model = models.Model(inputs=base.input, outputs=out)\n","    model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","print('Baseline model builder ready (EfficientNetB0)')"],"id":"0x_T_6DezNUQ"},{"cell_type":"markdown","metadata":{"id":"reMDfPVKzNUR"},"source":["## 5) Feature extraction pipeline (for ACO feature selection)\n","We extract deep embeddings (GlobalAveragePooling2D outputs) from the pretrained backbone, producing a fixed-length feature vector per image (e.g., 1280 dims for EfficientNetB0). Then we run Ant Colony Optimization to select a subset of those features."],"id":"reMDfPVKzNUR"},{"cell_type":"code","metadata":{"id":"UohvRPtBzNUR"},"execution_count":null,"outputs":[],"source":["def extract_features(model_backbone, dataset, batch_size=32):\n","    \"\"\"Given a model that outputs embeddings (e.g., base+gap), return X (n_samples x d) and y.\"\"\"\n","    features = []\n","    labels = []\n","    for batch in dataset:  # dataset yields (images, labels)\n","        imgs, labs = batch\n","        feats = model_backbone.predict(imgs)\n","        features.append(feats)\n","        labels.append(labs.numpy())\n","    X = np.vstack(features)\n","    y = np.concatenate(labels)\n","    return X, y\n","\n","print('Feature extraction helper ready')"],"id":"UohvRPtBzNUR"},{"cell_type":"markdown","metadata":{"id":"pChyGAnEzNUR"},"source":["### 5.a Build an embedding model (backbone->GAP)\n","We'll reuse EfficientNetB0 backbone and create a model that returns the pooled features."],"id":"pChyGAnEzNUR"},{"cell_type":"code","metadata":{"id":"eY59imsJzNUS"},"execution_count":null,"outputs":[],"source":["from tensorflow.keras.models import Model\n","backbone = EfficientNetB0(include_top=False, input_shape=(224,224,3), weights='imagenet')\n","gap = layers.GlobalAveragePooling2D()(backbone.output)\n","embed_model = Model(inputs=backbone.input, outputs=gap)\n","print('Embedding model ready — output dim =', embed_model.output_shape)"],"id":"eY59imsJzNUS"},{"cell_type":"markdown","metadata":{"id":"ElkgwBLszNUS"},"source":["## 6) Ant Colony Optimization (ACO) for feature selection\n","We apply ACO to select a subset of embedding features that maximize validation accuracy when training a small classifier on those features. For clarity we implement a simple ACO variant tailored to feature selection."],"id":"ElkgwBLszNUS"},{"cell_type":"code","metadata":{"id":"nf5do8SMzNUT"},"execution_count":null,"outputs":[],"source":["import random\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","\n","def aco_feature_selection(X, y, n_ants=20, n_iters=25, alpha=1.0, beta=2.0, rho=0.1, k_features=50):\n","    \"\"\"Simple ACO for selecting k_features indices from feature vector X. Returns best_indices.\n","    - X: (n_samples, n_features)\n","    - uses logistic regression as quick evaluator (CV accuracy)\n","    \"\"\"\n","    n_features = X.shape[1]\n","    # initialize pheromone\n","    pheromone = np.ones(n_features)\n","    best_solution = None\n","    best_score = 0.0\n","    for it in range(n_iters):\n","        all_solutions = []\n","        all_scores = []\n","        for ant in range(n_ants):\n","            probs = (pheromone ** alpha)\n","            probs = probs / probs.sum()\n","            # stochastic selection proportionally to pheromone\n","            chosen = np.random.choice(np.arange(n_features), size=k_features, replace=False, p=probs)\n","            Xsub = X[:, chosen]\n","            clf = LogisticRegression(max_iter=500)\n","            # quick 3-fold CV to score\n","            try:\n","                score = cross_val_score(clf, Xsub, y, cv=3, scoring='accuracy').mean()\n","            except Exception:\n","                score = 0.0\n","            all_solutions.append(chosen)\n","            all_scores.append(score)\n","            if score > best_score:\n","                best_score = score\n","                best_solution = chosen\n","        # pheromone evaporation\n","        pheromone = (1 - rho) * pheromone\n","        # deposit pheromone according to quality\n","        for sol, sc in zip(all_solutions, all_scores):\n","            for idx in sol:\n","                pheromone[idx] += sc\n","        print(f'Iter {it+1}/{n_iters} best_score={best_score:.4f}')\n","    return np.array(best_solution), best_score\n","\n","print('ACO feature selection function ready')"],"id":"nf5do8SMzNUT"},{"cell_type":"markdown","metadata":{"id":"ZPunUFAJzNUU"},"source":["## 7) Metaheuristic hyperparameter optimization wrappers\n","We will provide wrappers to tune a small set of hyperparameters of the classifier model: e.g., learning_rate, dropout, number_of_dense_units (or top layers), and number of fine-tuned layers. For Phase 1 we run four algorithms: PSO, Genetic Algorithm (GA using DEAP), Differential Evolution (scipy), and Simulated Annealing (custom)."],"id":"ZPunUFAJzNUU"},{"cell_type":"code","metadata":{"id":"2M9QSjOfzNUU"},"execution_count":null,"outputs":[],"source":["# Example objective: given a vector x (hyperparameters), build model, train for few epochs on small subset, return validation loss or negative accuracy.\n","def decode_vector(x):\n","    \"\"\"Decode float vector to meaningful hyperparameters.\n","    x: array [lr_log, dropout, dense_units_norm, fine_tune_frac]\n","    returns: dict\n","    \"\"\"\n","    lr = 10 ** (-5 + x[0] * 3)      # maps [0,1] -> [1e-5,1e-2]\n","    dropout = 0.05 + x[1] * 0.5    # maps [0,1] -> [0.05,0.55]\n","    dense = int(64 + x[2] * 448)   # [64,512]\n","    ft_frac = x[3]\n","    return {'lr': lr, 'dropout': dropout, 'dense': dense, 'ft_frac': ft_frac}\n","\n","def objective_fn(x, train_ds, val_ds, num_classes):\n","    params = decode_vector(x)\n","    # Build model with params\n","    model = build_baseline_model(num_classes, dropout=params['dropout'], lr=params['lr'])\n","    # Optionally unfreeze top layers according to ft_frac\n","    total_layers = len(model.layers)\n","    n_unfreeze = int(total_layers * params['ft_frac'])\n","    if n_unfreeze > 0:\n","        for layer in model.layers[-n_unfreeze:]:\n","            try:\n","                layer.trainable = True\n","            except Exception:\n","                pass\n","    # Train for a few epochs (fast eval)\n","    history = model.fit(train_ds, validation_data=val_ds, epochs=3, verbose=0)\n","    val_acc = history.history['val_accuracy'][-1]\n","    # Return negative val_acc as minimizer\n","    return -float(val_acc)\n","\n","print('Objective and decoder ready')"],"id":"2M9QSjOfzNUU"},{"cell_type":"markdown","metadata":{"id":"rPgRNXE6zNUV"},"source":["### 7.a PSO using pyswarms\n","We search in [0,1]^4 space which the decode_vector maps into hyperparameters."],"id":"rPgRNXE6zNUV"},{"cell_type":"code","metadata":{"id":"eE5az24bzNUW"},"execution_count":null,"outputs":[],"source":["import pyswarms as ps\n","def run_pso(train_ds, val_ds, num_classes, n_particles=12, iters=20):\n","    def f(x):\n","        # pyswarms passes x as (n_particles, dimensions)\n","        out = []\n","        for row in x:\n","            out.append(objective_fn(row, train_ds, val_ds, num_classes))\n","        return np.array(out)\n","    options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n","    optimizer = ps.single.GlobalBestPSO(n_particles=n_particles, dimensions=4, options=options)\n","    best_cost, best_pos = optimizer.optimize(f, iters=iters)\n","    return best_pos, best_cost\n","\n","print('PSO wrapper ready')"],"id":"eE5az24bzNUW"},{"cell_type":"markdown","metadata":{"id":"xMGD2CvMzNUX"},"source":["### 7.b Differential Evolution (scipy)\n","Use `scipy.optimize.differential_evolution` on the 4-d box [0,1]^4. It expects a function that returns scalar to minimize."],"id":"xMGD2CvMzNUX"},{"cell_type":"code","metadata":{"id":"1ECoJzMGzNUX"},"execution_count":null,"outputs":[],"source":["from scipy.optimize import differential_evolution\n","def run_de(train_ds, val_ds, num_classes, maxiter=10):\n","    bounds = [(0,1)]*4\n","    def f(x):\n","        return objective_fn(x, train_ds, val_ds, num_classes)\n","    res = differential_evolution(f, bounds, maxiter=maxiter, polish=False)\n","    return res.x, res.fun\n","\n","print('DE wrapper ready')"],"id":"1ECoJzMGzNUX"},{"cell_type":"markdown","metadata":{"id":"sqqa3bnAzNUX"},"source":["### 7.c Genetic Algorithm (DEAP)\n","We use DEAP to implement a simple GA searching in [0,1]^4."],"id":"sqqa3bnAzNUX"},{"cell_type":"code","metadata":{"id":"j2OcMsVwzNUY"},"execution_count":null,"outputs":[],"source":["import random\n","from deap import base, creator, tools, algorithms\n","\n","def run_ga(train_ds, val_ds, num_classes, ngen=10, pop=12):\n","    creator.create('FitnessMin', base.Fitness, weights=(-1.0,))\n","    creator.create('Individual', list, fitness=creator.FitnessMin)\n","    toolbox = base.Toolbox()\n","    toolbox.register('attr_float', random.random)\n","    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_float, n=4)\n","    toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n","    def eval_ind(ind):\n","        return (objective_fn(np.array(ind), train_ds, val_ds, num_classes),)\n","    toolbox.register('evaluate', eval_ind)\n","    toolbox.register('mate', tools.cxBlend, alpha=0.5)\n","    toolbox.register('mutate', tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n","    toolbox.register('select', tools.selTournament, tournsize=3)\n","    popu = toolbox.population(n=pop)\n","    hof = tools.HallOfFame(1)\n","    algorithms.eaSimple(popu, toolbox, cxpb=0.5, mutpb=0.2, ngen=ngen, halloffame=hof, verbose=True)\n","    best = hof.items[0]\n","    return np.array(best), best.fitness.values[0]\n","\n","print('GA wrapper ready (DEAP)')"],"id":"j2OcMsVwzNUY"},{"cell_type":"markdown","metadata":{"id":"JGtfuCzQzNUZ"},"source":["### 7.d Simulated Annealing (custom)\n","Simple annealing on the 4-d continuous space with gaussian proposals.\n"],"id":"JGtfuCzQzNUZ"},{"cell_type":"code","metadata":{"id":"Gfd24w8wzNUZ"},"execution_count":null,"outputs":[],"source":["def run_sa(train_ds, val_ds, num_classes, n_iters=50, T0=1.0, alpha=0.95):\n","    # start from random\n","    x = np.random.rand(4)\n","    fx = objective_fn(x, train_ds, val_ds, num_classes)\n","    best_x, best_fx = x.copy(), fx\n","    T = T0\n","    for i in range(n_iters):\n","        cand = x + np.random.normal(scale=0.1, size=4)\n","        cand = np.clip(cand, 0, 1)\n","        f_cand = objective_fn(cand, train_ds, val_ds, num_classes)\n","        if f_cand < fx or np.random.rand() < np.exp((fx - f_cand)/T):\n","            x, fx = cand, f_cand\n","            if fx < best_fx:\n","                best_x, best_fx = x.copy(), fx\n","        T *= alpha\n","    return best_x, best_fx\n","\n","print('SA wrapper ready')"],"id":"Gfd24w8wzNUZ"},{"cell_type":"markdown","metadata":{"id":"_RP8fxzCzNUa"},"source":["## 8) Evaluation & comparison\n","After running each optimization, record: best hyperparameters, validation accuracy, training time (per trial), and optionally confusion matrix on test set."],"id":"_RP8fxzCzNUa"},{"cell_type":"markdown","metadata":{"id":"3xtAelwCzNUa"},"source":["## 9) Notes on reproducibility and runtime\n"," - The notebook focuses on a reproducible pipeline. For hyperparameter search we train for a few epochs for fast evaluation; for the final selected hyperparameters, retrain with more epochs and possibly unfreeze backbone.\n"," - If dataset is large, consider sampling a subset for fast metaheuristic runs, or use small image size during search.\n"," - Placeholders for visualization (training curves, confusion matrix, Grad-CAM) are included in the report/presentation code below."],"id":"3xtAelwCzNUa"}]}