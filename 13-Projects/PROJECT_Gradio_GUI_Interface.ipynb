{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12051,
     "status": "ok",
     "timestamp": 1746967035698,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -180
    },
    "id": "jxVbmjAam6CP",
    "outputId": "bd5e3013-5997-46b3-d90b-149945bcef29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.10.0 (from gradio)\n",
      "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
      "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "executionInfo": {
     "elapsed": 9126,
     "status": "error",
     "timestamp": 1746967046773,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -180
    },
    "id": "Uqklruq0h0rZ",
    "outputId": "fa998b71-6c8d-4c68-ef7f-fd027651f08d"
   },
   "outputs": [
    {
     "ename": "MessageError",
     "evalue": "Error: credential propagation was unsuccessful",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "executionInfo": {
     "elapsed": 15630,
     "status": "ok",
     "timestamp": 1746967070763,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -180
    },
    "id": "7SJDknzQm9hI",
    "outputId": "80bfb25c-c3fd-457c-aec9-ef8636cac98b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from best_cnn_model.h5\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://d3e0923eea52a141ec.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d3e0923eea52a141ec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Load your CNN model\n",
    "def load_cnn_model(model_path):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"Model loaded successfully from {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to your model file\n",
    "model_path = \"best_cnn_model.h5\"\n",
    "\n",
    "# Try to load the model\n",
    "model = load_cnn_model(model_path)\n",
    "\n",
    "# Define class names\n",
    "CLASS_NAMES = [\"ball\", \"circle cage\", \"cube\", \"cylinder\", \"human body\",\n",
    "              \"metal bucket\", \"plane\", \"rov\", \"square cage\", \"tyre\"]\n",
    "\n",
    "# Define preprocessing function to match training\n",
    "def preprocess_image(img):\n",
    "\n",
    "    # Convert PIL Image to OpenCV format (RGB to BGR)\n",
    "    img_cv = np.array(img)\n",
    "    if len(img_cv.shape) == 3 and img_cv.shape[2] == 3:\n",
    "        img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize image to the size your model expects\n",
    "    target_size = (64, 64)\n",
    "    img_resized = cv2.resize(img_cv, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "    img_processed = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "    img_processed = np.expand_dims(img_processed, axis=-1)  # Add channel dimension\n",
    "    img_processed = img_resized\n",
    "    img_normalized = img_processed.astype(np.float32) / 255.0\n",
    "    img_batch = np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "    return img_batch\n",
    "\n",
    "# Function to draw detection results on the image\n",
    "def draw_results(img, predicted_class, confidence, top_3_classes=None):\n",
    "    # Convert to a format we can draw on\n",
    "    draw_img = img.copy()\n",
    "    draw = ImageDraw.Draw(draw_img)\n",
    "    width, height = img.size\n",
    "\n",
    "    # Color mapping based on confidence\n",
    "    if confidence < 0.3:\n",
    "        color = \"red\"  # Low confidence\n",
    "    elif confidence < 0.7:\n",
    "        color = \"yellow\"  # Medium confidence\n",
    "    else:\n",
    "        color = \"green\"  # High confidence\n",
    "\n",
    "    # Draw bounding box (50% of image size, centered)\n",
    "    rect_width = width * 0.6\n",
    "    rect_height = height * 0.6\n",
    "    left = (width - rect_width) / 2\n",
    "    top = (height - rect_height) / 2\n",
    "    right = left + rect_width\n",
    "    bottom = top + rect_height\n",
    "\n",
    "    # Draw rectangle with thicker border for better visibility\n",
    "    line_width = max(3, int(min(width, height) / 100))\n",
    "    draw.rectangle([left, top, right, bottom], outline=color, width=line_width)\n",
    "\n",
    "    # Try to load a font that supports all characters\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"Arial.ttf\", 20)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Draw label with confidence\n",
    "    label = f\"{predicted_class}: {confidence:.1%}\"\n",
    "    text_width, text_height = draw.textsize(label, font=font) if hasattr(draw, 'textsize') else (len(label)*10, 20)\n",
    "\n",
    "    # Create a semi-transparent background for text\n",
    "    draw.rectangle([left, top - text_height - 10, left + text_width + 10, top],\n",
    "                  fill=(0, 0, 0, 128))\n",
    "\n",
    "    # Draw text\n",
    "    draw.text((left + 5, top - text_height - 5), label, fill=color, font=font)\n",
    "\n",
    "    # If top 3 classes are provided, show them at the bottom\n",
    "    if top_3_classes:\n",
    "        y_pos = bottom + 10\n",
    "        for cls, conf in top_3_classes:\n",
    "            text = f\"{cls}: {conf:.1%}\"\n",
    "            draw.rectangle([left, y_pos, left + text_width + 10, y_pos + text_height + 5],\n",
    "                         fill=(0, 0, 0, 128))\n",
    "            draw.text((left + 5, y_pos), text, fill=\"white\", font=font)\n",
    "            y_pos += text_height + 10\n",
    "\n",
    "    return draw_img\n",
    "\n",
    "# Function to apply data augmentation for better visualization\n",
    "def visualize_augmentations(img, predicted_class):\n",
    "    aug_results = []\n",
    "    original_img = np.array(img)\n",
    "\n",
    "    # Resize to model input size and then back for consistency\n",
    "    target_size = (64, 64)\n",
    "    aug_img = cv2.resize(original_img, target_size)\n",
    "    aug_img = cv2.resize(aug_img, (img.width, img.height))\n",
    "    aug_results.append((\"Original (Resized)\", Image.fromarray(aug_img)))\n",
    "\n",
    "    # 1. Brightness adjustment\n",
    "    aug_img = np.array(img) * 0.8  # Darker\n",
    "    aug_img = np.clip(aug_img, 0, 255).astype(np.uint8)\n",
    "    aug_results.append((\"Darker\", Image.fromarray(aug_img)))\n",
    "\n",
    "    # 2. Brightness adjustment\n",
    "    aug_img = np.array(img) * 1.2  # Brighter\n",
    "    aug_img = np.clip(aug_img, 0, 255).astype(np.uint8)\n",
    "    aug_results.append((\"Brighter\", Image.fromarray(aug_img)))\n",
    "\n",
    "    # 3. Add noise\n",
    "    aug_img = np.array(img)\n",
    "    noise = np.random.normal(0, 15, aug_img.shape).astype(np.uint8)\n",
    "    aug_img = np.clip(aug_img + noise, 0, 255).astype(np.uint8)\n",
    "    aug_results.append((\"Noisy\", Image.fromarray(aug_img)))\n",
    "\n",
    "    # 4. Blur\n",
    "    aug_img = np.array(img)\n",
    "    aug_img = cv2.GaussianBlur(aug_img, (5, 5), 0)\n",
    "    aug_results.append((\"Blurred\", Image.fromarray(aug_img)))\n",
    "\n",
    "    return aug_results\n",
    "\n",
    "# Define prediction function with better error handling and debugging\n",
    "def predict(img):\n",
    "    if img is None:\n",
    "        return None, None, {\"error\": \"Please provide an image\"}\n",
    "\n",
    "    if model is None:\n",
    "        return None, None, {\"error\": \"Model could not be loaded. Please check the model path and format.\"}\n",
    "\n",
    "    try:\n",
    "        # Store original image for visualization\n",
    "        original_img = img.copy()\n",
    "\n",
    "        # Preprocess the image\n",
    "        processed_img = preprocess_image(img)\n",
    "\n",
    "        # Debug info about processed image\n",
    "        print(f\"Processed image shape: {processed_img.shape}\")\n",
    "        print(f\"Processed image min: {np.min(processed_img)}, max: {np.max(processed_img)}\")\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = model.predict(processed_img)\n",
    "\n",
    "        # Debug info about prediction\n",
    "        print(f\"Prediction type: {type(prediction)}\")\n",
    "        if isinstance(prediction, list):\n",
    "            for i, p in enumerate(prediction):\n",
    "                print(f\"Prediction[{i}] shape: {p.shape}\")\n",
    "        else:\n",
    "            print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "        # Parse prediction results\n",
    "        result_json = {}\n",
    "        top_3_classes = []\n",
    "\n",
    "        # Handle different output types\n",
    "        if isinstance(prediction, list):\n",
    "            # If model has multiple outputs (e.g., bbox + class)\n",
    "            if len(prediction) >= 2:\n",
    "                # Assuming first element is bounding box and second is class\n",
    "                class_pred = prediction[1]\n",
    "                class_pred = class_pred[0]  # Get first batch item\n",
    "            else:\n",
    "                class_pred = prediction[0][0]\n",
    "        elif isinstance(prediction, np.ndarray):\n",
    "            if len(prediction.shape) == 2:\n",
    "                class_pred = prediction[0]  # First batch item\n",
    "            else:\n",
    "                # Handle unusual output shapes\n",
    "                class_pred = prediction.flatten()[:len(CLASS_NAMES)]\n",
    "        else:\n",
    "            return img, None, {\"error\": f\"Unexpected prediction type: {type(prediction)}\"}\n",
    "\n",
    "        # Print raw predictions for debugging\n",
    "        print(\"Raw class predictions:\")\n",
    "        for i, score in enumerate(class_pred):\n",
    "            if i < len(CLASS_NAMES):\n",
    "                print(f\"{CLASS_NAMES[i]}: {score:.4f}\")\n",
    "\n",
    "        # Get predicted class and confidence\n",
    "        predicted_class_idx = np.argmax(class_pred)\n",
    "        predicted_class = CLASS_NAMES[predicted_class_idx]\n",
    "        confidence = float(class_pred[predicted_class_idx])\n",
    "\n",
    "        # Get top 3 predictions for display\n",
    "        top_indices = np.argsort(class_pred)[-3:][::-1]\n",
    "        top_3_classes = [(CLASS_NAMES[i], float(class_pred[i])) for i in top_indices]\n",
    "\n",
    "        # Create result JSON\n",
    "        result_json[\"Predicted Class\"] = predicted_class\n",
    "        result_json[\"Confidence\"] = f\"{confidence:.2%}\"\n",
    "\n",
    "        # Add top 3 classes to results\n",
    "        for cls, conf in top_3_classes:\n",
    "            result_json[f\"{cls}\"] = f\"{conf:.2%}\"\n",
    "\n",
    "        # Create augmentation grid for debugging\n",
    "        aug_results = visualize_augmentations(original_img, predicted_class)\n",
    "        aug_grid = Image.new('RGB', (original_img.width * 3, original_img.height * 2))\n",
    "\n",
    "        # Place original image with detection\n",
    "        img_with_detection = draw_results(original_img, predicted_class, confidence, top_3_classes)\n",
    "        aug_grid.paste(img_with_detection, (0, 0))\n",
    "\n",
    "        # Place augmented versions\n",
    "        for i, (aug_name, aug_img) in enumerate(aug_results):\n",
    "            if i >= 5:  # Limit to 5 augmentations\n",
    "                break\n",
    "            row, col = divmod(i + 1, 3)\n",
    "            aug_grid.paste(aug_img, (col * original_img.width, row * original_img.height))\n",
    "\n",
    "        return img_with_detection, aug_grid, result_json\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_details = traceback.format_exc()\n",
    "        print(f\"Detailed error: {error_details}\")\n",
    "        return img, None, {\"error\": f\"Prediction failed: {str(e)}\"}\n",
    "\n",
    "# the Gradio interface with layout\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Input Image\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Detection Result\"),\n",
    "        gr.Image(type=\"pil\", label=\"Augmentation Tests\"),\n",
    "        gr.JSON(label=\"Prediction Details\")\n",
    "    ],\n",
    "    title=\"Underwater Object Detection DL Model\",\n",
    "    description=\"\"\"\n",
    "    Upload an underwater sonar image to detect objects using the CNN model.\n",
    "\n",
    "    The detection shows:\n",
    "    1. The predicted object class with confidence score\n",
    "    2. A bounding box highlighting the detected object\n",
    "    3. Alternative augmentations to test model robustness\n",
    "\n",
    "    The model can detect: ball, circle cage, cube, cylinder, human body, metal bucket, plane, ROV, square cage, tyre\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Qo_6hEcQKJu1P3uHwWKszMJpowMMEIW9",
     "timestamp": 1746904980421
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
