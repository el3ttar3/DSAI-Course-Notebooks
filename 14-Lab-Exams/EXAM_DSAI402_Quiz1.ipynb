{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["cbz9B-T0t3lu"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#yourNAME, yourID"],"metadata":{"id":"5mJVJ15PuDnJ"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"BVmskFXtt9ck"}},{"cell_type":"code","source":["import gymnasium as gym\n","from gymnasium import spaces\n","import numpy as np"],"metadata":{"id":"qLc35GaOt8PX","executionInfo":{"status":"ok","timestamp":1762212231365,"user_tz":-120,"elapsed":553,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# LuffyDodge (3)"],"metadata":{"id":"B3tcl2yet_iq"}},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true,"id":"CV2uRUPNoNLy","executionInfo":{"status":"ok","timestamp":1762213057975,"user_tz":-120,"elapsed":45,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"}}},"outputs":[],"source":["class LuffyDodgeEnv(gym.Env):\n","    \"\"\"\n","    Custom environment where Luffy must dodge cannonballs.\n","    Luffy can move left, right, or stay still to avoid being hit.\n","    \"\"\"\n","\n","    metadata = {\"render_modes\": [\"human\"]}\n","\n","    def __init__(self, render_mode=None):\n","        \"\"\"\n","        Initialize environment parameters.\n","        \"\"\"\n","        super(LuffyDodgeEnv, self).__init__()\n","\n","        # Actions: 0 = left, 1 = stay, 2 = right\n","        self.action_space = spaces.Discrete(3)\n","\n","        # Observation: [Luffy_x, Cannonball_x, Cannonball_y]\n","        self.observation_space = spaces.Box(\n","            low=np.array([0, 0, 0], dtype=np.float32),\n","            high=np.array([9, 9, 9], dtype=np.float32),\n","            dtype=np.float32\n","        )\n","\n","        self.render_mode = render_mode\n","        self.reset()\n","\n","    def reset(self, seed=None, options=None):\n","        \"\"\"\n","        Reset the environment to its initial state.\n","        \"\"\"\n","        super().reset(seed=seed)\n","\n","        # Luffy starts in the middle bottom\n","        self.luffy_x = 5.0\n","\n","        # Cannonball starts at a random x and top y = 9\n","        self.cannon_x = np.random.randint(0, 10)\n","        self.cannon_y = 9.0\n","\n","        # Return initial observation\n","        obs = np.array([self.luffy_x, self.cannon_x, self.cannon_y], dtype=np.float32)\n","        return obs, {}\n","\n","    def step(self, action):\n","\n","        # Step 1: Update Luffy's position based on action\n","      if action == 0:  # Move left\n","          self.luffy_x = max(0.0, self.luffy_x - 1.0)\n","      elif action == 2:  # Move right\n","          self.luffy_x = min(9.0, self.luffy_x + 1.0)\n","        # action == 1 means stay still, so no change to luffy_x\n","\n","        # Step 2: Move cannonball down by one step\n","      self.cannon_y -= 1.0\n","\n","        # Step 3: Check for collision\n","        # Collision happens when cannonball reaches y=0 and has same x as Luffy\n","      if self.cannon_y == 0.0 and int(self.luffy_x) == int(self.cannon_x):\n","            # Hit! Game over\n","            reward = -10.0\n","            done = True\n","            truncated = False\n","      elif self.cannon_y < 0.0:\n","            # Cannonball missed Luffy and went past bottom\n","            # Reset cannonball to top with random x position\n","            self.cannon_x = np.random.randint(0, 10)\n","            self.cannon_y = 9.0\n","            reward = +1.0\n","            done = False\n","            truncated = False\n","      else:\n","            # Cannonball is still falling, Luffy survived this step\n","            reward = +1.0\n","            done = False\n","            truncated = False\n","\n","        # Step 4: Return observation and other info\n","      obs = np.array([self.luffy_x, self.cannon_x, self.cannon_y], dtype=np.float32)\n","      info = {}\n","\n","      return obs, reward, done, truncated, info\n","\n","    def render(self):\n","        \"\"\"\n","        Render the environment as simple text output.\n","        \"\"\"\n","        grid = np.full((10, 10), \" \", dtype=str)\n","        grid[int(self.cannon_y), int(self.cannon_x)] = \"O\"\n","        grid[0, int(self.luffy_x)] = \"L\"\n","        print(\"\\n\".join([\"\".join(row) for row in grid[::-1]]))\n","        print(\"-\" * 10)\n","\n","    def close(self):\n","        \"\"\"Close the environment.\"\"\"\n","        pass"]},{"cell_type":"code","source":["env = LuffyDodgeEnv()\n","obs, _ = env.reset()\n","\n","done = False\n","while not done:\n","    action = env.action_space.sample()\n","    obs, reward, done, truncated, info = env.step(action)\n","    env.render()\n","    print(f\"Action: {action}, Reward: {reward}\")"],"metadata":{"id":"Px1liZDDt0Tb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762213172313,"user_tz":-120,"elapsed":92,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"}},"outputId":"806e8855-e42c-45bc-fef9-fb4bc900ba12"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","      L   \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n","       L  \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","       L  \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","      L   \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","      L   \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","     L    \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","    L     \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","    L     \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O  L     \n","----------\n","Action: 1, Reward: 1.0\n","      O   \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","   L      \n","----------\n","Action: 0, Reward: 1.0\n","          \n","      O   \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","    L     \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","      O   \n","          \n","          \n","          \n","          \n","          \n","          \n","    L     \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","      O   \n","          \n","          \n","          \n","          \n","          \n","     L    \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","      O   \n","          \n","          \n","          \n","          \n","     L    \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","      O   \n","          \n","          \n","          \n","    L     \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","      O   \n","          \n","          \n","    L     \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","      O   \n","          \n","   L      \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","      O   \n","  L       \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L    O   \n","----------\n","Action: 0, Reward: 1.0\n","         O\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 2, Reward: 1.0\n","          \n","         O\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","         O\n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","         O\n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","         O\n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","         O\n","          \n","          \n","          \n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","         O\n","          \n","          \n","L         \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","         O\n","          \n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","         O\n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","L        O\n","----------\n","Action: 1, Reward: 1.0\n","       O  \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","L         \n","----------\n","Action: 1, Reward: 1.0\n","          \n","       O  \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","       O  \n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","       O  \n","          \n","          \n","          \n","          \n","          \n","   L      \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","       O  \n","          \n","          \n","          \n","          \n","    L     \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","       O  \n","          \n","          \n","          \n","   L      \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","       O  \n","          \n","          \n","    L     \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","       O  \n","          \n","   L      \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","       O  \n","    L     \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","    L  O  \n","----------\n","Action: 1, Reward: 1.0\n","         O\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","     L    \n","----------\n","Action: 2, Reward: 1.0\n","          \n","         O\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","     L    \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","         O\n","          \n","          \n","          \n","          \n","          \n","          \n","    L     \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","         O\n","          \n","          \n","          \n","          \n","          \n","   L      \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","         O\n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","         O\n","          \n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","         O\n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","         O\n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","         O\n","   L      \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","  L      O\n","----------\n","Action: 0, Reward: 1.0\n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n","   L      \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","   L      \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","    L     \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","    L     \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","   L      \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","    L     \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","    L     \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O L      \n","----------\n","Action: 0, Reward: 1.0\n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","   L      \n","----------\n","Action: 1, Reward: 1.0\n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n","          \n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","          \n","   L      \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","          \n","   L      \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O        \n","  L       \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," O L      \n","----------\n","Action: 2, Reward: 1.0\n","O         \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 0, Reward: 1.0\n","          \n","O         \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","O         \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","O         \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","O         \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","O         \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","O         \n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","O         \n","          \n"," L        \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","O         \n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","OL        \n","----------\n","Action: 2, Reward: 1.0\n","   O      \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","   O      \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","   O      \n","          \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","   O      \n","          \n","          \n","          \n","          \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","   O      \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","   O      \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","   O      \n","          \n","          \n","  L       \n","----------\n","Action: 2, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","   O      \n","          \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","   O      \n","  L       \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L O      \n","----------\n","Action: 0, Reward: 1.0\n","O         \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","O         \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","O         \n","          \n","          \n","          \n","          \n","          \n","          \n"," L        \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","O         \n","          \n","          \n","          \n","          \n","          \n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","O         \n","          \n","          \n","          \n","          \n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","O         \n","          \n","          \n","          \n","L         \n","----------\n","Action: 0, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","O         \n","          \n","          \n","L         \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","O         \n","          \n","L         \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","O         \n","L         \n","----------\n","Action: 1, Reward: 1.0\n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","          \n","L         \n","----------\n","Action: 1, Reward: -10.0\n"]}]},{"cell_type":"markdown","source":["# Policy Evaluation (2)"],"metadata":{"id":"cbz9B-T0t3lu"}},{"cell_type":"code","source":["# Grid size\n","GRID_SIZE = 5\n","\n","# Actions: 0 = left, 1 = stay, 2 = right\n","ACTIONS = [0, 1, 2]\n","NUM_ACTIONS = len(ACTIONS)\n","\n","# All possible states: (Luffy_x, Cannon_x, Cannon_y)\n","states = [(lx, cx, cy) for lx in range(GRID_SIZE)\n","                         for cx in range(GRID_SIZE)\n","                         for cy in range(GRID_SIZE)]\n","NUM_STATES = len(states)\n","\n","# Initialize policy randomly\n","policy = np.random.choice(ACTIONS, size=NUM_STATES)\n","\n","# Initialize value function\n","V = np.zeros(NUM_STATES)\n","\n","# Discount factor\n","gamma = 0.9\n","\n","\n","def state_to_index(state):\n","    \"\"\"Convert a (luffy_x, cannon_x, cannon_y) state tuple into its index in the state list.\"\"\"\n","    lx, cx, cy = state\n","    return lx * GRID_SIZE * GRID_SIZE + cx * GRID_SIZE + cy\n","\n","\n","def transition(state, action):\n","    \"\"\"\n","    Deterministic transition function for the environment.\n","\n","    Parameters\n","    ----------\n","    state : tuple (luffy_x, cannon_x, cannon_y)\n","    action : int (0=left, 1=stay, 2=right)\n","\n","    Returns\n","    -------\n","    next_state : tuple or None\n","        Next state after taking the action.\n","    reward : float\n","        Reward received after the transition.\n","    done : bool\n","        Whether the episode terminates (Luffy hit by cannonball).\n","    \"\"\"\n","    lx, cx, cy = state\n","\n","    # Move Luffy\n","    if action == 0:\n","        lx = max(0, lx - 1)\n","    elif action == 2:\n","        lx = min(GRID_SIZE - 1, lx + 1)\n","\n","    # Move cannonball down\n","    cy -= 1\n","\n","    # Check terminal condition\n","    if cy < 0:\n","        if lx == cx:\n","            # Hit\n","            return None, -10.0, True\n","        else:\n","            # Miss → reset cannonball to top\n","            return (lx, cx, GRID_SIZE - 1), +1.0, False\n","\n","    # Otherwise just one step closer to bottom\n","    return (lx, cx, cy), +1.0, False\n","\n","\n","def policy_evaluation(policy, V, theta=1e-4):\n","\n","    while True:\n","        delta = 0.0\n","\n","        # Loop through all states\n","        for s, state in enumerate(states):\n","            # Save old value\n","            v_old = V[s]\n","\n","            # Get action from policy\n","            action = policy[s]\n","\n","            # Get transition\n","            next_state, reward, done = transition(state, action)\n","\n","            # Bellman update\n","            if done:\n","                V[s] = reward\n","            else:\n","                next_state_index = state_to_index(next_state)\n","                V[s] = reward + gamma * V[next_state_index]\n","\n","            # Track maximum change\n","            delta = max(delta, abs(v_old - V[s]))\n","\n","        # Check convergence\n","        if delta < theta:\n","            break\n","\n","    return V\n","\n","\n","def policy_improvement(V, policy):\n","    \"\"\"Greedy policy improvement based on the current value function.\"\"\"\n","    policy_stable = True\n","    for s, state in enumerate(states):\n","        old_action = policy[s]\n","        action_values = []\n","\n","        # Try all actions and pick the best one\n","        for a in ACTIONS:\n","            next_state, reward, done = transition(state, a)\n","            if done:\n","                action_values.append(reward)\n","            else:\n","                action_values.append(reward + gamma * V[state_to_index(next_state)])\n","\n","        best_action = np.argmax(action_values)\n","        policy[s] = best_action\n","\n","        # Check if policy changed\n","        if old_action != best_action:\n","            policy_stable = False\n","    return policy, policy_stable\n","\n","\n","def policy_iteration():\n","    \"\"\"Run the full policy iteration loop.\"\"\"\n","    global V, policy\n","    iteration = 0\n","    while True:\n","        iteration += 1\n","        V = policy_evaluation(policy, V)\n","        policy, stable = policy_improvement(V, policy)\n","        print(f\"Iteration {iteration} completed.\")\n","        if stable:\n","            print(\"✅ Policy converged!\")\n","            break\n","    return policy, V\n","\n","\n","if __name__ == \"__main__\":\n","    optimal_policy, optimal_V = policy_iteration()\n","\n","    print(\"\\nOptimal policy (sample of 10 states):\")\n","    for i in range(10):\n","        print(f\"State {states[i]} → Action {optimal_policy[i]}\")\n"],"metadata":{"id":"8qV9XOHIpzUn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762213742378,"user_tz":-120,"elapsed":127,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"}},"outputId":"460ec412-69b2-44a1-ef26-240a56a032cc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1 completed.\n","Iteration 2 completed.\n","Iteration 3 completed.\n","Iteration 4 completed.\n","Iteration 5 completed.\n","Iteration 6 completed.\n","Iteration 7 completed.\n","Iteration 8 completed.\n","Iteration 9 completed.\n","Iteration 10 completed.\n","Iteration 11 completed.\n","Iteration 12 completed.\n","Iteration 13 completed.\n","Iteration 14 completed.\n","Iteration 15 completed.\n","Iteration 16 completed.\n","Iteration 17 completed.\n","Iteration 18 completed.\n","Iteration 19 completed.\n","Iteration 20 completed.\n","Iteration 21 completed.\n","Iteration 22 completed.\n","Iteration 23 completed.\n","Iteration 24 completed.\n","Iteration 25 completed.\n","Iteration 26 completed.\n","Iteration 27 completed.\n","Iteration 28 completed.\n","Iteration 29 completed.\n","Iteration 30 completed.\n","Iteration 31 completed.\n","Iteration 32 completed.\n","Iteration 33 completed.\n","Iteration 34 completed.\n","Iteration 35 completed.\n","Iteration 36 completed.\n","✅ Policy converged!\n","\n","Optimal policy (sample of 10 states):\n","State (0, 0, 0) → Action 2\n","State (0, 0, 1) → Action 0\n","State (0, 0, 2) → Action 0\n","State (0, 0, 3) → Action 0\n","State (0, 0, 4) → Action 0\n","State (0, 1, 0) → Action 0\n","State (0, 1, 1) → Action 0\n","State (0, 1, 2) → Action 0\n","State (0, 1, 3) → Action 0\n","State (0, 1, 4) → Action 0\n"]}]}]}