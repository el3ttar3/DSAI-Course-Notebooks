{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44993,"status":"ok","timestamp":1747236359132,"user":{"displayName":"Abdulrahman Mohammed 202201353","userId":"07518075019330847785"},"user_tz":-180},"id":"vptfqmLVms-Z","outputId":"67a2d3b8-9229-494f-d4c7-b549243a7201"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gradio\n","  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles\u003c25.0,\u003e=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio\u003c5.0,\u003e=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi\u003c1.0,\u003e=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.10.0 (from gradio)\n","  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx\u003e=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub\u003e=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\n","Requirement already satisfied: jinja2\u003c4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe\u003c4.0,\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy\u003c3.0,\u003e=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas\u003c3.0,\u003e=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow\u003c12.0,\u003e=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic\u003c2.12,\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart\u003e=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml\u003c7.0,\u003e=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff\u003e=0.9.3 (from gradio)\n","  Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx\u003c0.2.0,\u003e=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette\u003c1.0,\u003e=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit\u003c0.14.0,\u003e=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer\u003c1.0,\u003e=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn\u003e=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0-\u003egradio) (2025.3.2)\n","Requirement already satisfied: websockets\u003c16.0,\u003e=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0-\u003egradio) (15.0.1)\n","Requirement already satisfied: idna\u003e=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio\u003c5.0,\u003e=3.0-\u003egradio) (3.10)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio\u003c5.0,\u003e=3.0-\u003egradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (1.0.9)\n","Requirement already satisfied: h11\u003e=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*-\u003ehttpx\u003e=0.24.1-\u003egradio) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.28.1-\u003egradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.28.1-\u003egradio) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.28.1-\u003egradio) (4.67.1)\n","Requirement already satisfied: hf-xet\u003c2.0.0,\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.28.1-\u003egradio) (1.1.0)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2025.2)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c2.12,\u003e=2.0-\u003egradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c2.12,\u003e=2.0-\u003egradio) (2.33.2)\n","Requirement already satisfied: typing-inspection\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c2.12,\u003e=2.0-\u003egradio) (0.4.0)\n","Requirement already satisfied: click\u003e=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer\u003c1.0,\u003e=0.12-\u003egradio) (8.1.8)\n","Requirement already satisfied: shellingham\u003e=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer\u003c1.0,\u003e=0.12-\u003egradio) (1.5.4)\n","Requirement already satisfied: rich\u003e=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer\u003c1.0,\u003e=0.12-\u003egradio) (13.9.4)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas\u003c3.0,\u003e=1.0-\u003egradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich\u003e=10.11.0-\u003etyper\u003c1.0,\u003e=0.12-\u003egradio) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich\u003e=10.11.0-\u003etyper\u003c1.0,\u003e=0.12-\u003egradio) (2.19.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.28.1-\u003egradio) (3.4.2)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.28.1-\u003egradio) (2.4.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003e=10.11.0-\u003etyper\u003c1.0,\u003e=0.12-\u003egradio) (0.1.2)\n","Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"]}],"source":["!pip install gradio\n","import os\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sentence_transformers import SentenceTransformer\n","import gradio as gr\n","import time\n","import matplotlib.pyplot as plt\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.manifold import TSNE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":864},"id":"2BPIfQdkla71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading question data...\n","✅ Question data loaded successfully!\n","Found 30 questions in the database\n","Embedding dimension: 768\n","Loading transformer model...\n","Creating compatible encoder model...\n","✅ Model created successfully!\n","\n","Testing the system with example queries:\n","Query: How can I apply to Zewail City?\n","Best match: How can I apply to Zewail City?\n","Confidence: high (1.00)\n","Answer: To apply to Zewail City, visit the official website, create an account, fill out the online applicat...\n","\n","Creating Gradio interface...\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://5adcbeea22069a8e1a.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://5adcbeea22069a8e1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import h5py\n","from sentence_transformers import SentenceTransformer\n","import gradio as gr\n","import time\n","import matplotlib.pyplot as plt\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.manifold import TSNE\n","from tensorflow.keras import layers, Model, Input\n","\n","model_dir = '/content/'\n","\n","try:\n","    # Load the saved data\n","    print(\"Loading question data...\")\n","    with open(os.path.join(model_dir, 'question_data.pkl'), 'rb') as f:\n","        saved_data = pickle.load(f)\n","        questions_df = pd.DataFrame(saved_data['questions'])\n","        question_to_embedding = saved_data['question_to_embedding']\n","        optimal_threshold = saved_data.get('optimal_threshold', 0.6)  # Default if missing\n","\n","    print(\"✅ Question data loaded successfully!\")\n","    print(f\"Found {len(questions_df)} questions in the database\")\n","\n","    # Get a sample embedding to determine dimension\n","    sample_embedding = list(question_to_embedding.values())[0]\n","    embedding_dim = sample_embedding.shape[0]\n","    print(f\"Embedding dimension: {embedding_dim}\")\n","\n","    # Load the transformer model\n","    print(\"Loading transformer model...\")\n","    transformer_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n","\n","    # Create a compatible model\n","    print(\"Creating compatible encoder model...\")\n","    inputs = Input(shape=(embedding_dim,))\n","    x = layers.Dense(128, activation='relu')(inputs)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(0.3)(x)\n","    x = layers.Dense(64, activation='relu')(x)\n","    x = layers.Dense(32, activation='tanh')(x)\n","    encoder_model = Model(inputs=inputs, outputs=x)\n","    encoder_model.compile(optimizer='adam', loss='mse')\n","\n","    print(\"✅ Model created successfully!\")\n","\n","except Exception as e:\n","    print(f\"Error in initialization: {e}\")\n","    raise\n","\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = ' '.join(text.split())\n","    return text\n","\n","def find_most_similar_question(query, questions_df, transformer_model, encoder_model, threshold=optimal_threshold):\n","    # Preprocess the query\n","    processed_query = preprocess_text(query)\n","\n","    # Get transformer embedding for query\n","    query_transformer_embedding = transformer_model.encode([processed_query])[0]\n","\n","    # Get Siamese embedding for query\n","    query_siamese_embedding = encoder_model.predict(np.array([query_transformer_embedding]).reshape(1, -1), verbose=0)[0]\n","\n","    # Calculate most similar questions with original transformer embeddings\n","    similarities = []\n","    for q in questions_df['processed_question'] if 'processed_question' in questions_df.columns else questions_df['question']:\n","        q_processed = q if 'processed_question' in questions_df.columns else preprocess_text(q)\n","        if q_processed in question_to_embedding:\n","            q_embedding = question_to_embedding[q_processed]\n","            # Transform embedding through the model\n","            q_siamese_embedding = encoder_model.predict(np.array([q_embedding]).reshape(1, -1), verbose=0)[0]\n","            # Calculate similarity\n","            similarity = cosine_similarity([query_siamese_embedding], [q_siamese_embedding])[0][0]\n","            similarities.append(similarity)\n","        else:\n","            similarities.append(0)\n","\n","    # Find the most similar question\n","    max_similarity_idx = np.argmax(similarities)\n","    max_similarity = similarities[max_similarity_idx]\n","\n","    # Determine confidence level\n","    if max_similarity \u003e= 0.8:\n","        confidence = \"high\"\n","        emoji = \"✅\"\n","        explanation = \"I'm very confident about this answer.\"\n","    elif max_similarity \u003e= 0.6:\n","        confidence = \"medium\"\n","        emoji = \"⚠️\"\n","        explanation = \"I believe this is the correct answer, but please verify.\"\n","    else:\n","        confidence = \"low\"\n","        emoji = \"❓\"\n","        explanation = \"I'm not entirely sure this answers your question. Consider rephrasing.\"\n","\n","    # Get the best match\n","    best_match = questions_df.iloc[max_similarity_idx]\n","\n","    return {\n","        \"question\": best_match['question'],\n","        \"answer\": best_match['answer'],\n","        \"similarity\": max_similarity,\n","        \"confidence\": confidence,\n","        \"emoji\": emoji,\n","        \"explanation\": explanation\n","    }\n","\n","def visualize_query_similarity(query):\n","    # Preprocess the query\n","    processed_query = preprocess_text(query)\n","\n","    # Get transformer embedding for query\n","    query_transformer_embedding = transformer_model.encode([processed_query])[0]\n","\n","    # Get Siamese embedding for query\n","    query_siamese_embedding = encoder_model.predict(np.array([query_transformer_embedding]).reshape(1, -1), verbose=0)[0]\n","\n","    # Get all questions\n","    processed_questions = questions_df['processed_question'].tolist() if 'processed_question' in questions_df.columns else [preprocess_text(q) for q in questions_df['question'].tolist()]\n","    question_texts = questions_df['question'].tolist()\n","\n","    # Get embeddings for visualization\n","    question_embeddings = []\n","    for q in processed_questions:\n","        if q in question_to_embedding:\n","            q_transformer_embedding = question_to_embedding[q]\n","            q_siamese_embedding = encoder_model.predict(np.array([q_transformer_embedding]).reshape(1, -1), verbose=0)[0]\n","            question_embeddings.append(q_siamese_embedding)\n","        else:\n","            q_transformer_embedding = transformer_model.encode([q])[0]\n","            q_siamese_embedding = encoder_model.predict(np.array([q_transformer_embedding]).reshape(1, -1), verbose=0)[0]\n","            question_embeddings.append(q_siamese_embedding)\n","\n","    # TSNE for visualization\n","    all_embeddings = np.vstack([question_embeddings, query_siamese_embedding])\n","    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(all_embeddings)-1))\n","    embeddings_2d = tsne.fit_transform(all_embeddings)\n","\n","    # Create plot\n","    plt.figure(figsize=(10, 8))\n","\n","    # Calculate similarities for coloring\n","    similarities = [cosine_similarity([query_siamese_embedding], [q_emb])[0][0] for q_emb in question_embeddings]\n","\n","    # Plot the points\n","    scatter = plt.scatter(\n","        embeddings_2d[:len(question_texts), 0],\n","        embeddings_2d[:len(question_texts), 1],\n","        c=similarities,\n","        cmap='coolwarm',\n","        alpha=0.7,\n","        s=100\n","    )\n","\n","    # Plot the query point\n","    plt.scatter(\n","        embeddings_2d[-1, 0],\n","        embeddings_2d[-1, 1],\n","        marker='*',\n","        color='gold',\n","        s=200,\n","        edgecolor='black',\n","        linewidth=1,\n","        label='Your Query'\n","    )\n","\n","    # Add colorbar and annotations\n","    plt.colorbar(scatter, label=\"Similarity to Query\")\n","    top_indices = np.argsort(similarities)[-3:][::-1]\n","    for idx in top_indices:\n","        plt.annotate(\n","            f\"Q{idx+1}: {question_texts[idx][:30]}...\",\n","            (embeddings_2d[idx, 0], embeddings_2d[idx, 1]),\n","            xytext=(5, 5),\n","            textcoords='offset points',\n","            fontsize=8,\n","            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.7)\n","        )\n","\n","    plt.title(f\"Query Similarity Map\\nQuery: '{query}'\")\n","    plt.tight_layout()\n","\n","    return plt\n","\n","# --- Test the Model ---\n","print(\"\\nTesting the system with example queries:\")\n","test_query = \"How can I apply to Zewail City?\"\n","result = find_most_similar_question(test_query, questions_df, transformer_model, encoder_model)\n","print(f\"Query: {test_query}\")\n","print(f\"Best match: {result['question']}\")\n","print(f\"Confidence: {result['confidence']} ({result['similarity']:.2f})\")\n","print(f\"Answer: {result['answer'][:100]}...\")\n","\n","def gradio_answer_query(query, history, visualize=False):\n","    \"\"\"Process user query and return response with updated chat history\"\"\"\n","    if not query.strip():\n","        return \"\", history, None\n","\n","    # Get answer using the Siamese network\n","    start_time = time.time()\n","    result = find_most_similar_question(query, questions_df, transformer_model, encoder_model)\n","    response_time = time.time() - start_time\n","\n","    # Format response based on confidence levels\n","    formatted_response = f\"{result['emoji']} **{result['confidence'].title()} Confidence** (Score: {result['similarity']:.2f})\\n\\n\"\n","    formatted_response += f\"Your question matched: \\\"{result['question']}\\\"\\n\\n\"\n","    formatted_response += f\"**Answer:** {result['answer']}\\n\\n\"\n","    formatted_response += f\"*{result['explanation']}*\"\n","\n","    # Add response time\n","    formatted_response += f\"\\n\\n\u003csmall\u003eResponse time: {response_time*1000:.1f} ms\u003c/small\u003e\"\n","\n","    # Create visualization if requested\n","    visualization = None\n","    if visualize:\n","        visualization = visualize_query_similarity(query)\n","\n","    # Update history with proper message format for type=\"messages\"\n","    if history is None:\n","        history = []\n","\n","    # Use dictionary format with 'role' and 'content' keys\n","    history.append({\"role\": \"user\", \"content\": query})\n","    history.append({\"role\": \"assistant\", \"content\": formatted_response})\n","\n","    return \"\", history, visualization\n","\n","def add_text(text):\n","    return text\n","\n","def clear_chat():\n","    return None, None\n","\n","# --- Gradio Interface ---\n","custom_css = \"\"\"\n","body {\n","    font-family: 'Poppins', 'Segoe UI', sans-serif;\n","    background: linear-gradient(135deg, #f5f7fa 0%, #e4ecfb 100%);\n","}\n",".container {\n","    max-width: 1200px;\n","    margin: 0 auto;\n","}\n",".header {\n","    text-align: center;\n","    padding: 20px 0;\n","    background: linear-gradient(135deg, #1a365d 0%, #2c5282 100%);\n","    color: white;\n","    border-radius: 10px;\n","    margin-bottom: 20px;\n","    box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n","}\n",".footer {\n","    text-align: center;\n","    margin-top: 30px;\n","    font-size: 0.8em;\n","    color: #718096;\n","}\n",".chatbox {\n","    border-radius: 10px !important;\n","    overflow: hidden;\n","    box-shadow: 0 4px 15px rgba(0,0,0,0.1) !important;\n","}\n",".primary-btn {\n","    background: linear-gradient(135deg, #1a365d 0%, #2c5282 100%) !important;\n","    color: white !important;\n","    border: none !important;\n","    padding: 10px 20px !important;\n","    border-radius: 6px !important;\n","    transition: all 0.3s !important;\n","}\n",".primary-btn:hover {\n","    transform: translateY(-2px) !important;\n","    box-shadow: 0 4px 10px rgba(0,0,0,0.2) !important;\n","}\n",".example-chip {\n","    background: #e6f0ff !important;\n","    color: #1a365d !important;\n","    border: 1px solid #c3d8f5 !important;\n","    border-radius: 16px !important;\n","    padding: 5px 12px !important;\n","    font-size: 13px !important;\n","    transition: all 0.3s !important;\n","    cursor: pointer !important;\n","}\n",".example-chip:hover {\n","    background: #d1e2ff !important;\n","    transform: translateY(-1px) !important;\n","    box-shadow: 0 2px 5px rgba(0,0,0,0.1) !important;\n","}\n",".info-card {\n","    background: rgba(255,255,255,0.9);\n","    border-radius: 10px;\n","    padding: 15px;\n","    margin-bottom: 15px;\n","    box-shadow: 0 4px 15px rgba(0,0,0,0.05);\n","}\n",".visualization {\n","    margin-top: 20px;\n","    border-radius: 10px;\n","    overflow: hidden;\n","    box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n","}\n","\"\"\"\n","\n","# Create Gradio blocks interface\n","print(\"\\nCreating Gradio interface...\")\n","with gr.Blocks(css=custom_css) as demo:\n","    # Header\n","    gr.HTML(\"\"\"\n","    \u003cdiv class=\"header\"\u003e\n","        \u003ch1\u003eZewail City Admission Assistant\u003c/h1\u003e\n","        \u003cp\u003ePowered by Siamese Neural Network and Transformer Embeddings\u003c/p\u003e\n","    \u003c/div\u003e\n","    \"\"\")\n","\n","    with gr.Row():\n","        # Left column - Chat interface\n","        with gr.Column(scale=3):\n","            # Chat area\n","            chatbot = gr.Chatbot(\n","                label=\"Conversation\",\n","                height=500,\n","                elem_id=\"chatbox\",\n","                elem_classes=\"chatbox\",\n","                type=\"messages\",\n","            )\n","\n","            # Input area\n","            with gr.Row():\n","                query_input = gr.Textbox(\n","                    placeholder=\"Type your question about Zewail City admissions...\",\n","                    label=\"Your Question\",\n","                    lines=2,\n","                    max_lines=5,\n","                    show_label=False,\n","                    scale=4\n","                )\n","\n","                # Add visualization toggle\n","                visualize_toggle = gr.Checkbox(\n","                    label=\"Show Visualization\",\n","                    value=False,\n","                    scale=1,\n","                    info=\"Display a visualization of query similarity\"\n","                )\n","\n","                submit_btn = gr.Button(\"Ask\", variant=\"primary\", elem_classes=\"primary-btn\", scale=1)\n","\n","            with gr.Row():\n","                clear_btn = gr.Button(\"Clear Chat\", variant=\"secondary\")\n","\n","            # Visualization area (shows when visualization is enabled)\n","            visualization = gr.Plot(label=\"Query Similarity Visualization\", visible=True, elem_classes=\"visualization\")\n","\n","            # Example questions\n","            gr.HTML(\"\u003ch3\u003eExample Questions\u003c/h3\u003e\")\n","\n","            # Get unique example questions from the dataset (up to 8)\n","            example_questions = questions_df['question'].sample(min(8, len(questions_df))).tolist()\n","\n","            with gr.Row():\n","                # First row of examples (4)\n","                for question in example_questions[:4]:\n","                    # Limit the length of displayed questions\n","                    display_question = question if len(question) \u003c 40 else question[:37] + \"...\"\n","                    example_btn = gr.Button(display_question, elem_classes=\"example-chip\")\n","                    example_btn.click(\n","                        fn=lambda q=question: q,  # Use default parameter to capture current value\n","                        inputs=[],\n","                        outputs=[query_input]\n","                    ).then(\n","                        fn=gradio_answer_query,\n","                        inputs=[query_input, chatbot, visualize_toggle],\n","                        outputs=[query_input, chatbot, visualization]\n","                    )\n","\n","            with gr.Row():\n","                # Second row of examples (4)\n","                for question in example_questions[4:8]:\n","                    # Limit the length of displayed questions\n","                    display_question = question if len(question) \u003c 40 else question[:37] + \"...\"\n","                    example_btn = gr.Button(display_question, elem_classes=\"example-chip\")\n","                    example_btn.click(\n","                        fn=lambda q=question: q,  # Use default parameter to capture current value\n","                        inputs=[],\n","                        outputs=[query_input]\n","                    ).then(\n","                        fn=gradio_answer_query,\n","                        inputs=[query_input, chatbot, visualize_toggle],\n","                        outputs=[query_input, chatbot, visualization]\n","                    )\n","\n","        # Right column - Info\n","        with gr.Column(scale=2):\n","            # About Zewail City\n","            gr.HTML(\"\"\"\n","            \u003cdiv class=\"info-card\"\u003e\n","                \u003ch3\u003eAbout Zewail City\u003c/h3\u003e\n","                \u003cp\u003eZewail City of Science and Technology is a nonprofit, independent institution of learning,\n","                research and innovation founded by Nobel laureate Ahmed Zewail.\u003c/p\u003e\n","                \u003cp\u003e\u003cb\u003eContact:\u003c/b\u003e admissions@zewailcity.edu.eg\u003cbr\u003e\n","                \u003cb\u003ePhone:\u003c/b\u003e +20-1033077738\u003cbr\u003e\n","                \u003cb\u003eWebsite:\u003c/b\u003e \u003ca href=\"https://www.zewailcity.edu.eg\" target=\"_blank\"\u003ezewailcity.edu.eg\u003c/a\u003e\u003c/p\u003e\n","            \u003c/div\u003e\n","            \"\"\")\n","\n","            # How it works\n","            gr.HTML(\"\"\"\n","            \u003cdiv class=\"info-card\"\u003e\n","                \u003ch3\u003eHow it works\u003c/h3\u003e\n","                \u003cp\u003eThis chatbot uses advanced AI technology to understand and answer your questions:\u003c/p\u003e\n","                \u003col\u003e\n","                    \u003cli\u003e\u003cb\u003eTransformer Embeddings\u003c/b\u003e - Your question is processed by a state-of-the-art language model\u003c/li\u003e\n","                    \u003cli\u003e\u003cb\u003eSiamese Neural Network\u003c/b\u003e - A specialized neural network finds the most similar questions in our database\u003c/li\u003e\n","                    \u003cli\u003e\u003cb\u003eConfidence Scoring\u003c/b\u003e - The system provides a confidence level with each answer\u003c/li\u003e\n","                \u003c/ol\u003e\n","                \u003cp\u003eThe visualization shows where your query fits among known questions in the embedding space.\u003c/p\u003e\n","            \u003c/div\u003e\n","            \"\"\")\n","\n","            # Model information\n","            gr.HTML(f\"\"\"\n","            \u003cdiv class=\"info-card\"\u003e\n","                \u003ch3\u003eAI Model Details\u003c/h3\u003e\n","                \u003cp\u003eThis assistant uses your data with a compatible Siamese network.\u003c/p\u003e\n","                \u003cul\u003e\n","                    \u003cli\u003e\u003cb\u003eKnowledge base:\u003c/b\u003e {len(questions_df)} question-answer pairs\u003c/li\u003e\n","                    \u003cli\u003e\u003cb\u003eTransformer model:\u003c/b\u003e paraphrase-multilingual-mpnet-base-v2\u003c/li\u003e\n","                    \u003cli\u003e\u003cb\u003eEmbedding dimension:\u003c/b\u003e {embedding_dim} \u003c/li\u003e\n","                    \u003cli\u003e\u003cb\u003eSimilarity threshold:\u003c/b\u003e {optimal_threshold:.2f}\u003c/li\u003e\n","                \u003c/ul\u003e\n","            \u003c/div\u003e\n","            \"\"\")\n","\n","    # Footer\n","    gr.HTML(\"\"\"\n","    \u003cdiv class=\"footer\"\u003e\n","        \u003cp\u003eDeveloped with ❤️ for Zewail City | © 2025 All Rights Reserved\u003c/p\u003e\n","    \u003c/div\u003e\n","    \"\"\")\n","\n","    # Set up event handlers\n","    submit_btn.click(\n","        fn=gradio_answer_query,\n","        inputs=[query_input, chatbot, visualize_toggle],\n","        outputs=[query_input, chatbot, visualization]\n","    )\n","\n","    query_input.submit(\n","        fn=gradio_answer_query,\n","        inputs=[query_input, chatbot, visualize_toggle],\n","        outputs=[query_input, chatbot, visualization]\n","    )\n","\n","    clear_btn.click(\n","        fn=lambda: (None, None),  # Return None for both history and visualization\n","        inputs=None,\n","        outputs=[chatbot, visualization]\n","    )\n","\n","# Launch the interface\n","demo.launch(share=True, debug=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO2KzzDgSg0DbaVfWC2Y4bo","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}