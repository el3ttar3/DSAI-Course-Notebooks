{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnYDZYIy8AHj"
   },
   "source": [
    "# PHASE 1: DATA PREPROCESSING AND VISUALIZATION\n",
    "YouTube Video NLP Analysis Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49839,
     "status": "ok",
     "timestamp": 1762463132151,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -120
    },
    "id": "gI_hH1X-79hi",
    "outputId": "7acda6dc-98a6-4af1-ecfd-71558a4a3270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api==0.6.1 in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api==0.6.1) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api==0.6.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api==0.6.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api==0.6.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api==0.6.1) (2025.10.5)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.4)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
      "Downloading NLTK resources...\n",
      "Loading spaCy model...\n",
      "‚úì All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: SETUP & IMPORTS\n",
    "# =============================================================================\n",
    "!pip install youtube-transcript-api==0.6.1\n",
    "!pip install gensim\n",
    "# Basic libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# YouTube & Text Processing\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import spacy\n",
    "\n",
    "# Feature Extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except:\n",
    "    print(\"Installing sentence-transformers...\")\n",
    "    !pip install sentence-transformers\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Download NLTK data\n",
    "print(\"Downloading NLTK resources...\")\n",
    "for resource in ['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger']:\n",
    "    nltk.download(resource, quiet=True)\n",
    "\n",
    "# Load spaCy\n",
    "print(\"Loading spaCy model...\")\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except:\n",
    "    print(\"Installing spaCy model...\")\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1762463136922,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -120
    },
    "id": "64Hsp8sC82hm",
    "outputId": "3bddb015-d8f9-43b5-eaf2-a673f425bb67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  output_dir: phase1_outputs\n",
      "  max_videos: 10\n",
      "  embedding_dim: 100\n",
      "  tfidf_max_features: 1000\n",
      "  w2v_window: 5\n",
      "  w2v_min_count: 2\n",
      "  visualization_top_n: 20\n",
      "  sentence_transformer_model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Project configuration\n",
    "CONFIG = {\n",
    "    'output_dir': 'phase1_outputs',\n",
    "    'max_videos': 10,\n",
    "    'embedding_dim': 100,\n",
    "    'tfidf_max_features': 1000,\n",
    "    'w2v_window': 5,\n",
    "    'w2v_min_count': 2,\n",
    "    'visualization_top_n': 20,\n",
    "    'sentence_transformer_model': 'all-MiniLM-L6-v2'\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "Path(CONFIG['output_dir']).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1762463140694,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -120
    },
    "id": "MVahi6f789wX",
    "outputId": "5f94fc04-d0a7-4eda-de8d-8bebf1aed404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 2 videos queued for processing\n",
      "Video IDs:\n",
      "  - aircAruvnKk\n",
      "  - rfscVS0vtbw\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: YOUTUBE VIDEO LIST\n",
    "# =============================================================================\n",
    "\n",
    "# Educational YouTube Videos Dataset\n",
    "# Add your video URLs here\n",
    "VIDEO_URLS = [\n",
    "    # Machine Learning & AI\n",
    "    \"https://www.youtube.com/watch?v=aircAruvnKk\",  # 3Blue1Brown: Neural Networks\n",
    "    \"https://www.youtube.com/watch?v=rfscVS0vtbw\",  # Python for Beginners\n",
    "\n",
    "    #more URLs from:\n",
    "    # - Khan Academy\n",
    "    # - MIT OpenCourseWare\n",
    "    # - CrashCourse\n",
    "    # - 3Blue1Brown\n",
    "    # - StatQuest\n",
    "    # - Computerphile\n",
    "]\n",
    "\n",
    "print(f\"Dataset: {len(VIDEO_URLS)} videos queued for processing\")\n",
    "print(\"Video IDs:\")\n",
    "for url in VIDEO_URLS:\n",
    "    try:\n",
    "        video_id = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11})', url).group(1)\n",
    "        print(f\"  - {video_id}\")\n",
    "    except:\n",
    "        print(f\"  - Invalid URL: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3296,
     "status": "ok",
     "timestamp": 1762463152511,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -120
    },
    "id": "wOcjjPpG9uXy",
    "outputId": "f0be2367-04b3-4263-9fca-308c3c0b4457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIAGNOSTIC CHECK: YouTube Transcript API\n",
      "================================================================================\n",
      "\n",
      "[1/5] Checking import...\n",
      "‚úì youtube_transcript_api imported successfully\n",
      "\n",
      "[2/5] Checking version...\n",
      "‚ö†Ô∏è  Cannot determine version\n",
      "\n",
      "[3/5] Testing simple extraction method...\n",
      "‚úó Simple method failed: no element found: line 1, column 0\n",
      "\n",
      "[4/5] Testing advanced extraction method...\n",
      "‚úì Advanced method available!\n",
      "   Available transcripts: ['ar', 'bn', 'zh', 'zh-CN', 'zh-TW', 'cs', 'en', 'fil', 'fr', 'de', 'el', 'iw', 'hi', 'hu', 'it', 'ja', 'ko', 'mr', 'fa', 'fa-IR', 'pl', 'pt', 'pt-BR', 'ro', 'ru', 'es', 'th', 'tr', 'uk', 'ur', 'en']\n",
      "\n",
      "[5/5] Testing with your video URLs...\n",
      "Found 2 URLs to test\n",
      "  [1] ‚úó aircAruvnKk: no element found: line 1, column 0...\n",
      "  [2] ‚úó rfscVS0vtbw: no element found: line 1, column 0...\n",
      "\n",
      "================================================================================\n",
      "DIAGNOSTIC SUMMARY\n",
      "================================================================================\n",
      "‚úó SETUP ISSUES DETECTED\n",
      "\n",
      "Troubleshooting steps:\n",
      "1. Check internet connection\n",
      "2. Verify video URLs are correct\n",
      "3. Ensure videos have English transcripts (check on YouTube)\n",
      "4. Try: pip install --upgrade youtube-transcript-api\n",
      "5. Restart kernel after installing/upgrading\n",
      "================================================================================\n",
      "\n",
      "üìã RECOMMENDED NEXT STEPS:\n",
      "‚Üí Fix the issues above before proceeding\n",
      "‚Üí Replace any failed video URLs with alternatives\n",
      "‚Üí Ensure videos have captions/subtitles enabled\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DIAGNOSTIC CELL: RUN THIS FIRST TO CHECK YOUR SETUP\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DIAGNOSTIC CHECK: YouTube Transcript API\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check 1: Import test\n",
    "print(\"\\n[1/5] Checking import...\")\n",
    "try:\n",
    "    from youtube_transcript_api import YouTubeTranscriptApi\n",
    "    print(\"‚úì youtube_transcript_api imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(\"‚úó FAILED: youtube_transcript_api not installed\")\n",
    "    print(\"   Fix: pip install youtube-transcript-api\")\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Check 2: Version check\n",
    "print(\"\\n[2/5] Checking version...\")\n",
    "try:\n",
    "    import youtube_transcript_api\n",
    "    version = youtube_transcript_api.__version__\n",
    "    print(f\"‚úì Version: {version}\")\n",
    "\n",
    "    # Parse version\n",
    "    major, minor = map(int, version.split('.')[:2])\n",
    "    if major == 0 and minor < 5:\n",
    "        print(f\"‚ö†Ô∏è  WARNING: Old version detected (v{version})\")\n",
    "        print(\"   Recommendation: pip install --upgrade youtube-transcript-api\")\n",
    "        print(\"   Some features may not be available\")\n",
    "    else:\n",
    "        print(f\"‚úì Version is recent (v{version})\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Cannot determine version\")\n",
    "\n",
    "# Check 3: Test simple extraction\n",
    "print(\"\\n[3/5] Testing simple extraction method...\")\n",
    "try:\n",
    "    test_id = \"aircAruvnKk\"  # 3Blue1Brown video\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(test_id)\n",
    "    print(f\"‚úì Simple method works! Extracted {len(transcript)} segments\")\n",
    "    print(f\"   Sample: {transcript[0]['text'][:50]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Simple method failed: {e}\")\n",
    "\n",
    "# Check 4: Test advanced extraction (if available)\n",
    "print(\"\\n[4/5] Testing advanced extraction method...\")\n",
    "try:\n",
    "    test_id = \"aircAruvnKk\"\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(test_id)\n",
    "    print(\"‚úì Advanced method available!\")\n",
    "    print(f\"   Available transcripts: {[t.language_code for t in transcript_list]}\")\n",
    "except AttributeError:\n",
    "    print(\"‚ö†Ô∏è  Advanced method not available (old version)\")\n",
    "    print(\"   This is OK - simple method will be used\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Advanced method test failed: {e}\")\n",
    "\n",
    "# Check 5: Test with your video URLs\n",
    "print(\"\\n[5/5] Testing with your video URLs...\")\n",
    "print(f\"Found {len(VIDEO_URLS)} URLs to test\")\n",
    "\n",
    "test_results = []\n",
    "for i, url in enumerate(VIDEO_URLS[:3], 1):  # Test first 3 only\n",
    "    try:\n",
    "        # Extract video ID\n",
    "        import re\n",
    "        match = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11})', url)\n",
    "        if not match:\n",
    "            print(f\"  [{i}] ‚úó Invalid URL format: {url}\")\n",
    "            continue\n",
    "\n",
    "        video_id = match.group(1)\n",
    "\n",
    "        # Try extraction\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        words = sum(len(entry['text'].split()) for entry in transcript)\n",
    "        print(f\"  [{i}] ‚úì {video_id}: {words} words\")\n",
    "        test_results.append(True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [{i}] ‚úó {video_id}: {str(e)[:60]}...\")\n",
    "        test_results.append(False)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if all(test_results):\n",
    "    print(\"‚úì ALL TESTS PASSED!\")\n",
    "    print(\"   Your setup is ready. Proceed with data extraction.\")\n",
    "elif any(test_results):\n",
    "    print(\"‚ö†Ô∏è  PARTIAL SUCCESS\")\n",
    "    print(f\"   {sum(test_results)}/{len(test_results)} videos extracted successfully\")\n",
    "    print(\"   Some videos may not have transcripts. Consider replacing failed URLs.\")\n",
    "else:\n",
    "    print(\"‚úó SETUP ISSUES DETECTED\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Check internet connection\")\n",
    "    print(\"2. Verify video URLs are correct\")\n",
    "    print(\"3. Ensure videos have English transcripts (check on YouTube)\")\n",
    "    print(\"4. Try: pip install --upgrade youtube-transcript-api\")\n",
    "    print(\"5. Restart kernel after installing/upgrading\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Recommended action\n",
    "print(\"\\nüìã RECOMMENDED NEXT STEPS:\")\n",
    "if all(test_results):\n",
    "    print(\"‚Üí Proceed to Cell 4 (Data Extraction)\")\n",
    "else:\n",
    "    print(\"‚Üí Fix the issues above before proceeding\")\n",
    "    print(\"‚Üí Replace any failed video URLs with alternatives\")\n",
    "    print(\"‚Üí Ensure videos have captions/subtitles enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10587,
     "status": "ok",
     "timestamp": 1762462911869,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -120
    },
    "id": "YkVerEsT-ZhE",
    "outputId": "c9be9f65-0942-4e42-a03a-996252c71907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FIXING youtube-transcript-api INSTALLATION\n",
      "================================================================================\n",
      "\n",
      "[1/3] Uninstalling old/broken version...\n",
      "‚úì Old version removed\n",
      "\n",
      "[2/3] Installing fresh version...\n",
      "‚úì youtube-transcript-api v0.6.1 installed successfully\n",
      "\n",
      "[3/3] Verifying installation...\n",
      "\n",
      "‚úó Verification failed: cannot import name 'TooManyRequests' from 'youtube_transcript_api._errors' (/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_errors.py)\n",
      "\n",
      "================================================================================\n",
      "MANUAL INSTALLATION REQUIRED\n",
      "================================================================================\n",
      "\n",
      "Please follow these steps:\n",
      "\n",
      "1. Stop this notebook\n",
      "\n",
      "2. Open terminal/Anaconda Prompt and run:\n",
      "   pip uninstall youtube-transcript-api\n",
      "   pip install youtube-transcript-api==0.6.1\n",
      "\n",
      "3. Restart Jupyter:\n",
      "   jupyter notebook\n",
      "\n",
      "4. Reopen this notebook\n",
      "   Kernel ‚Üí Restart & Clear Output\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EMERGENCY FIX: Reinstall youtube-transcript-api\n",
    "# RUN THIS CELL FIRST, THEN RESTART KERNEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FIXING youtube-transcript-api INSTALLATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Uninstall old version\n",
    "print(\"\\n[1/3] Uninstalling old/broken version...\")\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"youtube-transcript-api\"])\n",
    "    print(\"‚úì Old version removed\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  No previous installation found (this is OK)\")\n",
    "\n",
    "# Step 2: Install fresh version\n",
    "print(\"\\n[2/3] Installing fresh version...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"youtube-transcript-api==0.6.1\"])\n",
    "    print(\"‚úì youtube-transcript-api v0.6.1 installed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Installation failed: {e}\")\n",
    "    print(\"\\nManual fix required:\")\n",
    "    print(\"1. Open terminal/command prompt\")\n",
    "    print(\"2. Run: pip uninstall youtube-transcript-api\")\n",
    "    print(\"3. Run: pip install youtube-transcript-api==0.6.1\")\n",
    "    print(\"4. Restart Jupyter kernel\")\n",
    "\n",
    "# Step 3: Verify installation\n",
    "print(\"\\n[3/3] Verifying installation...\")\n",
    "try:\n",
    "    # Force reload\n",
    "    if 'youtube_transcript_api' in sys.modules:\n",
    "        del sys.modules['youtube_transcript_api']\n",
    "\n",
    "    from youtube_transcript_api import YouTubeTranscriptApi\n",
    "    import youtube_transcript_api\n",
    "\n",
    "    print(f\"‚úì Import successful\")\n",
    "    print(f\"‚úì Version: {youtube_transcript_api.__version__}\")\n",
    "\n",
    "    # Test extraction\n",
    "    print(\"\\n[TEST] Trying to extract a sample video...\")\n",
    "    test_transcript = YouTubeTranscriptApi.get_transcript(\"aircAruvnKk\")\n",
    "    print(f\"‚úì SUCCESS! Extracted {len(test_transcript)} segments\")\n",
    "    print(f\"‚úì Sample text: {test_transcript[0]['text'][:60]}...\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ INSTALLATION FIXED!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n‚ö†Ô∏è  IMPORTANT: RESTART YOUR JUPYTER KERNEL NOW\")\n",
    "    print(\"   Kernel ‚Üí Restart & Clear Output\")\n",
    "    print(\"\\nThen proceed with Cell 4 (Data Extraction)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó Verification failed: {e}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MANUAL INSTALLATION REQUIRED\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nPlease follow these steps:\")\n",
    "    print(\"\\n1. Stop this notebook\")\n",
    "    print(\"\\n2. Open terminal/Anaconda Prompt and run:\")\n",
    "    print(\"   pip uninstall youtube-transcript-api\")\n",
    "    print(\"   pip install youtube-transcript-api==0.6.1\")\n",
    "    print(\"\\n3. Restart Jupyter:\")\n",
    "    print(\"   jupyter notebook\")\n",
    "    print(\"\\n4. Reopen this notebook\")\n",
    "    print(\"   Kernel ‚Üí Restart & Clear Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1796,
     "status": "ok",
     "timestamp": 1762463168123,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -120
    },
    "id": "TDsOlD129Dj8",
    "outputId": "f3646b24-b90f-4044-e6f4-dbe4db12996b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: EXTRACTING TRANSCRIPTS\n",
      "================================================================================\n",
      "\n",
      "[1/2] Processing: https://www.youtube.com/watch?v=aircAruvnKk\n",
      "‚úó Failed: Extraction failed for https://www.youtube.com/watch?v=aircAruvnKk: no element found: line 1, column 0\n",
      "\n",
      "[2/2] Processing: https://www.youtube.com/watch?v=rfscVS0vtbw\n",
      "‚úó Failed: Extraction failed for https://www.youtube.com/watch?v=rfscVS0vtbw: no element found: line 1, column 0\n",
      "\n",
      "================================================================================\n",
      "EXTRACTION COMPLETE: 0/2 successful\n",
      "================================================================================\n",
      "\n",
      "‚úì Saved: phase1_outputs/raw_transcripts.json\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: DATA EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "class YouTubeTranscriptExtractor:\n",
    "    \"\"\"Extract YouTube video transcripts with metadata\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.extracted_data = []\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_video_id(url: str) -> str:\n",
    "        \"\"\"Extract video ID from YouTube URL\"\"\"\n",
    "        patterns = [\n",
    "            r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*',\n",
    "            r'(?:embed\\/)([0-9A-Za-z_-]{11})',\n",
    "            r'^([0-9A-Za-z_-]{11})$'\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, url)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "        raise ValueError(f\"Invalid YouTube URL: {url}\")\n",
    "\n",
    "    def extract_transcript(self, video_url: str, language: str = 'en') -> Dict:\n",
    "        \"\"\"Extract transcript with full metadata\"\"\"\n",
    "        try:\n",
    "            video_id = self.extract_video_id(video_url)\n",
    "            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "\n",
    "            # Prefer manual transcripts\n",
    "            try:\n",
    "                transcript = transcript_list.find_manually_created_transcript([language])\n",
    "                is_auto = False\n",
    "            except:\n",
    "                transcript = transcript_list.find_generated_transcript([language])\n",
    "                is_auto = True\n",
    "\n",
    "            entries = transcript.fetch()\n",
    "            full_text = ' '.join([entry['text'] for entry in entries])\n",
    "\n",
    "            return {\n",
    "                'video_id': video_id,\n",
    "                'video_url': video_url,\n",
    "                'transcript': full_text,\n",
    "                'num_segments': len(entries),\n",
    "                'duration_seconds': entries[-1]['start'] + entries[-1]['duration'] if entries else 0,\n",
    "                'language': language,\n",
    "                'is_auto_generated': is_auto,\n",
    "                'word_count': len(full_text.split()),\n",
    "                'char_count': len(full_text),\n",
    "                'entries': entries  # Keep raw data\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Extraction failed for {video_url}: {str(e)}\")\n",
    "\n",
    "# Extract all transcripts\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: EXTRACTING TRANSCRIPTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "extractor = YouTubeTranscriptExtractor()\n",
    "transcripts_data = []\n",
    "failed_extractions = []\n",
    "\n",
    "for i, url in enumerate(VIDEO_URLS, 1):\n",
    "    print(f\"\\n[{i}/{len(VIDEO_URLS)}] Processing: {url}\")\n",
    "    try:\n",
    "        data = extractor.extract_transcript(url)\n",
    "        transcripts_data.append(data)\n",
    "\n",
    "        print(f\"‚úì Success!\")\n",
    "        print(f\"  Video ID: {data['video_id']}\")\n",
    "        print(f\"  Duration: {data['duration_seconds']:.0f}s ({data['duration_seconds']/60:.1f}min)\")\n",
    "        print(f\"  Words: {data['word_count']:,}\")\n",
    "        print(f\"  Auto-generated: {data['is_auto_generated']}\")\n",
    "\n",
    "        time.sleep(1)  # Respectful rate limiting\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Failed: {e}\")\n",
    "        failed_extractions.append({'url': url, 'error': str(e)})\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"EXTRACTION COMPLETE: {len(transcripts_data)}/{len(VIDEO_URLS)} successful\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Summary statistics\n",
    "if transcripts_data:\n",
    "    total_words = sum(d['word_count'] for d in transcripts_data)\n",
    "    total_duration = sum(d['duration_seconds'] for d in transcripts_data)\n",
    "\n",
    "    print(f\"\\nDataset Summary:\")\n",
    "    print(f\"  Total videos: {len(transcripts_data)}\")\n",
    "    print(f\"  Total words: {total_words:,}\")\n",
    "    print(f\"  Total duration: {total_duration/60:.1f} minutes\")\n",
    "    print(f\"  Average words/video: {total_words/len(transcripts_data):.0f}\")\n",
    "    print(f\"  Manual transcripts: {sum(not d['is_auto_generated'] for d in transcripts_data)}\")\n",
    "    print(f\"  Auto-generated: {sum(d['is_auto_generated'] for d in transcripts_data)}\")\n",
    "\n",
    "# Save raw data\n",
    "with open(f\"{CONFIG['output_dir']}/raw_transcripts.json\", 'w') as f:\n",
    "    json.dump(transcripts_data, f, indent=2)\n",
    "print(f\"\\n‚úì Saved: {CONFIG['output_dir']}/raw_transcripts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "error",
     "timestamp": 1762463176173,
     "user": {
      "displayName": "Abdulrahman Mohammed 202201353",
      "userId": "07518075019330847785"
     },
     "user_tz": -120
    },
    "id": "NMro-b5R7kvf",
    "outputId": "3152b5b5-5e43-4b90-b0ee-7a4b92cfde9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 2: TEXT PREPROCESSING\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PREPROCESSING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Preprocessing Summary:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1689685451.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPreprocessing Summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Save processed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, percentiles, include, exclude)\u001b[0m\n\u001b[1;32m  11974\u001b[0m         \u001b[0mmax\u001b[0m            \u001b[0mNaN\u001b[0m      \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11975\u001b[0m         \"\"\"\n\u001b[0;32m> 11976\u001b[0;31m         return describe_ndframe(\n\u001b[0m\u001b[1;32m  11977\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11978\u001b[0m             \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/methods/describe.py\u001b[0m in \u001b[0;36mdescribe_ndframe\u001b[0;34m(obj, include, exclude, percentiles)\u001b[0m\n\u001b[1;32m     89\u001b[0m         )\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         describer = DataFrameDescriber(\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/methods/describe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot describe a DataFrame without columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: TEXT PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "class TextPreprocessor:\n",
    "    \"\"\"Comprehensive NLP preprocessing pipeline\"\"\"\n",
    "\n",
    "    def __init__(self, remove_stopwords=True, apply_lemmatization=True):\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.apply_lemmatization = apply_lemmatization\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean text: URLs, timestamps, special chars\"\"\"\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'\\[\\d{2}:\\d{2}\\]', '', text)\n",
    "        text = re.sub(r'[^\\w\\s.,!?-]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        text = re.sub(r'([.!?])\\1+', r'\\1', text)\n",
    "        return text\n",
    "\n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"NLTK tokenization with lowercasing\"\"\"\n",
    "        return word_tokenize(text.lower())\n",
    "\n",
    "    def remove_stopwords_func(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"Remove English stopwords\"\"\"\n",
    "        return [t for t in tokens if t not in self.stop_words]\n",
    "\n",
    "    def remove_punctuation(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"Remove non-alphanumeric tokens\"\"\"\n",
    "        return [t for t in tokens if t.isalnum()]\n",
    "\n",
    "    def lemmatize_tokens(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"WordNet lemmatization\"\"\"\n",
    "        return [self.lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    def stem_tokens(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"Porter stemming\"\"\"\n",
    "        return [self.stemmer.stem(t) for t in tokens]\n",
    "\n",
    "    def preprocess(self, text: str) -> Dict:\n",
    "        \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "        cleaned = self.clean_text(text)\n",
    "        tokens = self.tokenize(cleaned)\n",
    "        original_tokens = tokens.copy()\n",
    "\n",
    "        tokens = self.remove_punctuation(tokens)\n",
    "        tokens_no_stop = self.remove_stopwords_func(tokens) if self.remove_stopwords else tokens\n",
    "        lemmatized = self.lemmatize_tokens(tokens_no_stop) if self.apply_lemmatization else tokens_no_stop\n",
    "        stemmed = self.stem_tokens(tokens_no_stop)\n",
    "\n",
    "        return {\n",
    "            'original_text': text,\n",
    "            'cleaned_text': cleaned,\n",
    "            'tokens': original_tokens,\n",
    "            'tokens_no_stopwords': tokens_no_stop,\n",
    "            'lemmatized': lemmatized,\n",
    "            'stemmed': stemmed,\n",
    "            'processed_text': ' '.join(lemmatized),\n",
    "            'word_count': len(lemmatized),\n",
    "            'unique_words': len(set(lemmatized)),\n",
    "            'lexical_diversity': len(set(lemmatized)) / len(lemmatized) if lemmatized else 0\n",
    "        }\n",
    "\n",
    "# Preprocess all transcripts\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 2: TEXT PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "preprocessor = TextPreprocessor(remove_stopwords=True, apply_lemmatization=True)\n",
    "processed_data = []\n",
    "\n",
    "for i, data in enumerate(transcripts_data, 1):\n",
    "    print(f\"\\n[{i}/{len(transcripts_data)}] Preprocessing: {data['video_id']}\")\n",
    "\n",
    "    result = preprocessor.preprocess(data['transcript'])\n",
    "    result['video_id'] = data['video_id']\n",
    "    result['video_url'] = data['video_url']\n",
    "    result['duration_seconds'] = data['duration_seconds']\n",
    "    result['is_auto_generated'] = data['is_auto_generated']\n",
    "\n",
    "    processed_data.append(result)\n",
    "\n",
    "    print(f\"  Original: {data['word_count']:,} words\")\n",
    "    print(f\"  After cleaning: {len(result['tokens_no_stopwords']):,} tokens\")\n",
    "    print(f\"  After lemmatization: {result['word_count']:,} tokens\")\n",
    "    print(f\"  Unique words: {result['unique_words']:,}\")\n",
    "    print(f\"  Lexical diversity: {result['lexical_diversity']:.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PREPROCESSING COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Preprocessing statistics\n",
    "preprocessing_stats = pd.DataFrame([\n",
    "    {\n",
    "        'video_id': d['video_id'],\n",
    "        'original_words': next(t['word_count'] for t in transcripts_data if t['video_id'] == d['video_id']),\n",
    "        'processed_tokens': d['word_count'],\n",
    "        'unique_tokens': d['unique_words'],\n",
    "        'lexical_diversity': d['lexical_diversity'],\n",
    "        'retention_rate': d['word_count'] / next(t['word_count'] for t in transcripts_data if t['video_id'] == d['video_id'])\n",
    "    }\n",
    "    for d in processed_data\n",
    "])\n",
    "\n",
    "print(\"\\nPreprocessing Summary:\")\n",
    "print(preprocessing_stats.describe())\n",
    "\n",
    "# Save processed data\n",
    "with open(f\"{CONFIG['output_dir']}/processed_transcripts.json\", 'w') as f:\n",
    "    json.dump(processed_data, f, indent=2)\n",
    "print(f\"\\n‚úì Saved: {CONFIG['output_dir']}/processed_transcripts.json\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 6: TEXT ANALYSIS & STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "class TextAnalyzer:\n",
    "    \"\"\"Comprehensive text statistics and linguistic analysis\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_statistics(text: str, tokens: List[str]) -> Dict:\n",
    "        \"\"\"Calculate text statistics\"\"\"\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        stats = {\n",
    "            'num_sentences': len(sentences),\n",
    "            'num_tokens': len(tokens),\n",
    "            'num_unique_tokens': len(set(tokens)),\n",
    "            'avg_word_length': np.mean([len(w) for w in tokens]) if tokens else 0,\n",
    "            'avg_sentence_length': len(tokens) / len(sentences) if sentences else 0,\n",
    "            'lexical_diversity': len(set(tokens)) / len(tokens) if tokens else 0,\n",
    "            'most_common_words': Counter(tokens).most_common(50)\n",
    "        }\n",
    "\n",
    "        sentence_lengths = [len(word_tokenize(s)) for s in sentences]\n",
    "        stats['sentence_length_mean'] = np.mean(sentence_lengths)\n",
    "        stats['sentence_length_std'] = np.std(sentence_lengths)\n",
    "        stats['sentence_length_min'] = np.min(sentence_lengths)\n",
    "        stats['sentence_length_max'] = np.max(sentence_lengths)\n",
    "\n",
    "        return stats\n",
    "\n",
    "    @staticmethod\n",
    "    def pos_analysis(text: str) -> Dict:\n",
    "        \"\"\"POS tagging with spaCy\"\"\"\n",
    "        doc = nlp(text[:1000000])  # Limit for performance\n",
    "        pos_counts = Counter([token.pos_ for token in doc])\n",
    "\n",
    "        return {\n",
    "            'pos_distribution': dict(pos_counts),\n",
    "            'num_nouns': pos_counts.get('NOUN', 0),\n",
    "            'num_verbs': pos_counts.get('VERB', 0),\n",
    "            'num_adjectives': pos_counts.get('ADJ', 0),\n",
    "            'num_adverbs': pos_counts.get('ADV', 0)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_entities(text: str) -> Dict:\n",
    "        \"\"\"Named Entity Recognition\"\"\"\n",
    "        doc = nlp(text[:1000000])\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        entity_counts = Counter([label for _, label in entities])\n",
    "\n",
    "        return {\n",
    "            'entities': entities[:100],\n",
    "            'entity_distribution': dict(entity_counts),\n",
    "            'num_entities': len(entities)\n",
    "        }\n",
    "\n",
    "# Analyze all texts\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 3: TEXT ANALYSIS & STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "analyzer = TextAnalyzer()\n",
    "analysis_results = []\n",
    "\n",
    "for i, data in enumerate(processed_data, 1):\n",
    "    print(f\"\\n[{i}/{len(processed_data)}] Analyzing: {data['video_id']}\")\n",
    "\n",
    "    stats = analyzer.compute_statistics(data['cleaned_text'], data['lemmatized'])\n",
    "    pos_analysis = analyzer.pos_analysis(data['cleaned_text'][:100000])\n",
    "    entities = analyzer.extract_entities(data['cleaned_text'][:100000])\n",
    "\n",
    "    result = {\n",
    "        'video_id': data['video_id'],\n",
    "        'statistics': stats,\n",
    "        'pos_analysis': pos_analysis,\n",
    "        'entities': entities\n",
    "    }\n",
    "\n",
    "    analysis_results.append(result)\n",
    "\n",
    "    print(f\"  Sentences: {stats['num_sentences']}\")\n",
    "    print(f\"  Tokens: {stats['num_tokens']:,}\")\n",
    "    print(f\"  Lexical diversity: {stats['lexical_diversity']:.3f}\")\n",
    "    print(f\"  Avg sentence length: {stats['avg_sentence_length']:.1f} words\")\n",
    "    print(f\"  Named entities: {entities['num_entities']}\")\n",
    "\n",
    "# Save analysis results\n",
    "with open(f\"{CONFIG['output_dir']}/analysis_results.json\", 'w') as f:\n",
    "    json.dump(analysis_results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úì Analysis complete!\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 7: WORD EMBEDDINGS - TF-IDF\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 4A: GENERATING TF-IDF EMBEDDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare documents\n",
    "documents = [d['processed_text'] for d in processed_data]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=CONFIG['tfidf_max_features'],\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"‚úì TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"‚úì Vocabulary Size: {len(feature_names)}\")\n",
    "print(f\"‚úì Sparsity: {(1.0 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])):.2%}\")\n",
    "\n",
    "# Top TF-IDF terms per document\n",
    "print(\"\\nTop 5 TF-IDF terms per video:\")\n",
    "for i, data in enumerate(processed_data):\n",
    "    doc_tfidf = tfidf_matrix[i].toarray()[0]\n",
    "    top_indices = doc_tfidf.argsort()[-5:][::-1]\n",
    "    top_terms = [(feature_names[idx], doc_tfidf[idx]) for idx in top_indices]\n",
    "\n",
    "    print(f\"\\n{data['video_id']}:\")\n",
    "    for term, score in top_terms:\n",
    "        print(f\"  {term}: {score:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 8: WORD EMBEDDINGS - WORD2VEC\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4B: TRAINING WORD2VEC EMBEDDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare tokenized documents\n",
    "tokenized_docs = [d['lemmatized'] for d in processed_data]\n",
    "\n",
    "# Train Word2Vec\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_docs,\n",
    "    vector_size=CONFIG['embedding_dim'],\n",
    "    window=CONFIG['w2v_window'],\n",
    "    min_count=CONFIG['w2v_min_count'],\n",
    "    workers=4,\n",
    "    sg=1,  # Skip-gram\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "print(f\"‚úì Word2Vec Model Trained\")\n",
    "print(f\"‚úì Vocabulary Size: {len(w2v_model.wv):,}\")\n",
    "print(f\"‚úì Vector Dimensions: {w2v_model.vector_size}\")\n",
    "\n",
    "# Test semantic relationships\n",
    "test_words = ['learn', 'model', 'data', 'algorithm', 'neural']\n",
    "available_test_words = [w for w in test_words if w in w2v_model.wv]\n",
    "\n",
    "if available_test_words:\n",
    "    print(f\"\\nSemantic Similarities:\")\n",
    "    for word in available_test_words[:3]:\n",
    "        similar = w2v_model.wv.most_similar(word, topn=5)\n",
    "        print(f\"\\n'{word}' is similar to:\")\n",
    "        for sim_word, score in similar:\n",
    "            print(f\"  {sim_word}: {score:.3f}\")\n",
    "\n",
    "# Save model\n",
    "w2v_model.save(f\"{CONFIG['output_dir']}/word2vec.model\")\n",
    "print(f\"\\n‚úì Saved: {CONFIG['output_dir']}/word2vec.model\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 9: SENTENCE EMBEDDINGS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4C: GENERATING SENTENCE EMBEDDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize Sentence Transformer\n",
    "sentence_model = SentenceTransformer(CONFIG['sentence_transformer_model'])\n",
    "\n",
    "# Extract sentences from first video (demo)\n",
    "sample_sentences = []\n",
    "for data in processed_data[:2]:  # First 2 videos\n",
    "    sents = sent_tokenize(data['cleaned_text'])[:20]  # First 20 sentences\n",
    "    sample_sentences.extend(sents)\n",
    "\n",
    "print(f\"Encoding {len(sample_sentences)} sentences...\")\n",
    "sentence_embeddings = sentence_model.encode(sample_sentences, show_progress_bar=True)\n",
    "\n",
    "print(f\"‚úì Sentence Embeddings Shape: {sentence_embeddings.shape}\")\n",
    "print(f\"‚úì Embedding Dimensions: {sentence_embeddings.shape[1]}\")\n",
    "\n",
    "# Save embeddings\n",
    "np.save(f\"{CONFIG['output_dir']}/sentence_embeddings.npy\", sentence_embeddings)\n",
    "with open(f\"{CONFIG['output_dir']}/sentences.json\", 'w') as f:\n",
    "    json.dump(sample_sentences, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Saved sentence embeddings\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 10: VISUALIZATION - WORD FREQUENCY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use first video for detailed visualization\n",
    "first_video = analysis_results[0]\n",
    "first_processed = processed_data[0]\n",
    "\n",
    "# Word Frequency Bar Chart\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "words, counts = zip(*first_video['statistics']['most_common_words'][:CONFIG['visualization_top_n']])\n",
    "bars = ax.bar(range(len(words)), counts, color='steelblue', edgecolor='navy', linewidth=1.2)\n",
    "ax.set_xticks(range(len(words)))\n",
    "ax.set_xticklabels(words, rotation=45, ha='right')\n",
    "ax.set_xlabel('Words', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Top {CONFIG[\"visualization_top_n\"]} Most Frequent Words - {first_video[\"video_id\"]}',\n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "           f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/word_frequency.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Saved: word_frequency.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 11: VISUALIZATION - WORD CLOUD\n",
    "# =============================================================================\n",
    "\n",
    "# Word Cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    background_color='white',\n",
    "    colormap='viridis',\n",
    "    max_words=100,\n",
    "    relative_scaling=0.5,\n",
    "    min_font_size=10\n",
    ").generate(first_processed['processed_text'])\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(f'Word Cloud - {first_video[\"video_id\"]}', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/wordcloud.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Saved: wordcloud.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 12: VISUALIZATION - TEXT STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "# Text Statistics Dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "stats = first_video['statistics']\n",
    "\n",
    "# 1. Basic Statistics\n",
    "ax1 = axes[0, 0]\n",
    "metrics = ['Sentences', 'Tokens', 'Unique\\nTokens', 'Avg Word\\nLength']\n",
    "values = [\n",
    "    stats['num_sentences'],\n",
    "    stats['num_tokens'],\n",
    "    stats['num_unique_tokens'],\n",
    "    stats['avg_word_length']\n",
    "]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "bars = ax1.barh(metrics, values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_xlabel('Count / Value', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Text Statistics Overview', fontsize=13, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, values)):\n",
    "    ax1.text(val, i, f'  {val:.1f}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Lexical Diversity\n",
    "ax2 = axes[0, 1]\n",
    "diversity_val = stats['lexical_diversity']\n",
    "ax2.bar(['Lexical Diversity'], [diversity_val], color='#95E1D3', edgecolor='black', linewidth=2)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_ylabel('Ratio', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Lexical Diversity (Unique/Total)', fontsize=13, fontweight='bold')\n",
    "ax2.axhline(y=diversity_val, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax2.text(0, diversity_val + 0.05, f'{diversity_val:.3f}', ha='center', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Sentence Length Statistics\n",
    "ax3 = axes[1, 0]\n",
    "sent_metrics = ['Mean', 'Std Dev', 'Min', 'Max']\n",
    "sent_values = [\n",
    "    stats['sentence_length_mean'],\n",
    "    stats['sentence_length_std'],\n",
    "    stats['sentence_length_min'],\n",
    "    stats['sentence_length_max']\n",
    "]\n",
    "colors3 = ['#A8E6CF', '#FFD3B6', '#FFAAA5', '#FF8B94']\n",
    "ax3.bar(sent_metrics, sent_values, color=colors3, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_ylabel('Words per Sentence', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Sentence Length Statistics', fontsize=13, fontweight='bold')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(sent_values):\n",
    "    ax3.text(i, val, f'{val:.1f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 4. Top Words Pie Chart\n",
    "ax4 = axes[1, 1]\n",
    "top_5 = stats['most_common_words'][:5]\n",
    "labels, sizes = zip(*top_5)\n",
    "colors4 = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#95E1D3']\n",
    "explode = (0.05, 0, 0, 0, 0)\n",
    "ax4.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90,\n",
    "       colors=colors4, explode=explode, shadow=True, textprops={'fontsize': 10, 'fontweight': 'bold'})\n",
    "ax4.set_title('Top 5 Words Distribution', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Comprehensive Text Analysis - {first_video[\"video_id\"]}',\n",
    "            fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/text_statistics.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Saved: text_statistics.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 13: VISUALIZATION - POS DISTRIBUTION\n",
    "# =============================================================================\n",
    "\n",
    "# POS Distribution\n",
    "pos_dist = first_video['pos_analysis']['pos_distribution']\n",
    "\n",
    "if pos_dist:\n",
    "    pos_tags = list(pos_dist.keys())\n",
    "    counts = list(pos_dist.values())\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    bars = plt.bar(pos_tags, counts, color='coral', edgecolor='darkred', linewidth=1.5)\n",
    "    plt.xlabel('Part-of-Speech Tags', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Count', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'Part-of-Speech Distribution - {first_video[\"video_id\"]}',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/pos_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úì Saved: pos_distribution.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 14: VISUALIZATION - NAMED ENTITIES\n",
    "# =============================================================================\n",
    "\n",
    "# Named Entities Distribution\n",
    "entity_dist = first_video['entities']['entity_distribution']\n",
    "\n",
    "if entity_dist:\n",
    "    # Filter to top entity types\n",
    "    sorted_entities = sorted(entity_dist.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    labels, counts = zip(*sorted_entities)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    bars = plt.barh(range(len(labels)), counts, color='teal', edgecolor='darkslategray', linewidth=1.5)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.xlabel('Count', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Entity Type', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'Named Entity Distribution - {first_video[\"video_id\"]}',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, counts)):\n",
    "        plt.text(val, i, f'  {val}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/entity_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úì Saved: entity_distribution.png\")\n",
    "\n",
    "    # Sample entities\n",
    "    print(\"\\nSample Named Entities:\")\n",
    "    for entity, label in first_video['entities']['entities'][:15]:\n",
    "        print(f\"  {entity} ({label})\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 15: VISUALIZATION - PCA EMBEDDINGS\n",
    "# =============================================================================\n",
    "\n",
    "# PCA Visualization of Word Embeddings\n",
    "print(\"\\nGenerating PCA visualization...\")\n",
    "\n",
    "if len(w2v_model.wv) > 50:\n",
    "    # Get top words for visualization\n",
    "    top_words = [word for word, _ in first_video['statistics']['most_common_words'][:100]\n",
    "                if word in w2v_model.wv][:50]\n",
    "\n",
    "    word_vectors = np.array([w2v_model.wv[word] for word in top_words])\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(word_vectors)\n",
    "\n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
    "                         c=range(len(embeddings_2d)), cmap='viridis',\n",
    "                         alpha=0.7, s=150, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "    # Add word labels\n",
    "    for i, word in enumerate(top_words):\n",
    "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                   fontsize=9, alpha=0.8, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "    plt.colorbar(scatter, label='Word Index')\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)',\n",
    "              fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)',\n",
    "              fontsize=12, fontweight='bold')\n",
    "    plt.title('Word Embeddings Visualization using PCA (Word2Vec)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/embeddings_pca.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"‚úì Saved: embeddings_pca.png\")\n",
    "    print(f\"‚úì Total variance explained: {sum(pca.explained_variance_ratio_):.1%}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 16: VISUALIZATION - t-SNE EMBEDDINGS\n",
    "# =============================================================================\n",
    "\n",
    "# t-SNE Visualization of Word Embeddings\n",
    "print(\"\\nGenerating t-SNE visualization...\")\n",
    "\n",
    "if len(w2v_model.wv) > 50:\n",
    "    # Use same top words\n",
    "    top_words_tsne = [word for word, _ in first_video['statistics']['most_common_words'][:80]\n",
    "                     if word in w2v_model.wv][:60]\n",
    "\n",
    "    word_vectors_tsne = np.array([w2v_model.wv[word] for word in top_words_tsne])\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, perplexity=20, random_state=42, n_iter=1000,\n",
    "                learning_rate=200)\n",
    "    embeddings_tsne = tsne.fit_transform(word_vectors_tsne)\n",
    "\n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    scatter = plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1],\n",
    "                         c=range(len(embeddings_tsne)), cmap='plasma',\n",
    "                         alpha=0.7, s=180, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "    # Add word labels with better positioning\n",
    "    for i, word in enumerate(top_words_tsne):\n",
    "        plt.annotate(word, (embeddings_tsne[i, 0], embeddings_tsne[i, 1]),\n",
    "                   fontsize=10, alpha=0.9, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.4', facecolor='lightblue',\n",
    "                            edgecolor='navy', alpha=0.6))\n",
    "\n",
    "    plt.colorbar(scatter, label='Word Index')\n",
    "    plt.xlabel('t-SNE Dimension 1', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('t-SNE Dimension 2', fontsize=12, fontweight='bold')\n",
    "    plt.title('Word Embeddings Visualization using t-SNE (Word2Vec)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/embeddings_tsne.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úì Saved: embeddings_tsne.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 17: VISUALIZATION - WORD SIMILARITY HEATMAP\n",
    "# =============================================================================\n",
    "\n",
    "# Word Similarity Heatmap\n",
    "print(\"\\nGenerating word similarity heatmap...\")\n",
    "\n",
    "if len(w2v_model.wv) > 20:\n",
    "    # Select important words for similarity analysis\n",
    "    important_words = ['learn', 'model', 'data', 'algorithm', 'neural',\n",
    "                      'train', 'network', 'function', 'system', 'problem']\n",
    "\n",
    "    # Filter to words in vocabulary\n",
    "    available_words = [w for w in important_words if w in w2v_model.wv]\n",
    "\n",
    "    if len(available_words) >= 5:\n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = np.zeros((len(available_words), len(available_words)))\n",
    "\n",
    "        for i, word1 in enumerate(available_words):\n",
    "            for j, word2 in enumerate(available_words):\n",
    "                similarity_matrix[i, j] = w2v_model.wv.similarity(word1, word2)\n",
    "\n",
    "        # Create heatmap\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(similarity_matrix,\n",
    "                   xticklabels=available_words,\n",
    "                   yticklabels=available_words,\n",
    "                   annot=True,\n",
    "                   fmt='.3f',\n",
    "                   cmap='coolwarm',\n",
    "                   center=0.5,\n",
    "                   vmin=0,\n",
    "                   vmax=1,\n",
    "                   cbar_kws={'label': 'Cosine Similarity'},\n",
    "                   linewidths=1,\n",
    "                   linecolor='gray')\n",
    "\n",
    "        plt.title('Word Similarity Heatmap (Word2Vec Cosine Similarity)',\n",
    "                 fontsize=14, fontweight='bold', pad=15)\n",
    "        plt.xlabel('Words', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Words', fontsize=12, fontweight='bold')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{CONFIG['output_dir']}/similarity_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"‚úì Saved: similarity_heatmap.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 18: VISUALIZATION - SENTENCE EMBEDDINGS (t-SNE)\n",
    "# =============================================================================\n",
    "\n",
    "# Sentence Embeddings Visualization\n",
    "print(\"\\nGenerating sentence embeddings visualization...\")\n",
    "\n",
    "if len(sentence_embeddings) >= 10:\n",
    "    # Apply t-SNE to sentence embeddings\n",
    "    perplexity_val = min(5, len(sentence_embeddings) - 1)\n",
    "    tsne_sent = TSNE(n_components=2, perplexity=perplexity_val,\n",
    "                    random_state=42, n_iter=1000)\n",
    "    sent_embeddings_2d = tsne_sent.fit_transform(sentence_embeddings)\n",
    "\n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(16, 12))\n",
    "\n",
    "    # Color by sentence index (proxy for temporal order)\n",
    "    colors = np.arange(len(sent_embeddings_2d))\n",
    "    scatter = plt.scatter(sent_embeddings_2d[:, 0], sent_embeddings_2d[:, 1],\n",
    "                         c=colors, cmap='rainbow', alpha=0.6, s=100,\n",
    "                         edgecolors='black', linewidth=1)\n",
    "\n",
    "    # Add sentence preview labels for first 15\n",
    "    for i in range(min(15, len(sample_sentences))):\n",
    "        preview = sample_sentences[i][:40] + \"...\" if len(sample_sentences[i]) > 40 else sample_sentences[i]\n",
    "        plt.annotate(f\"{i+1}: {preview}\",\n",
    "                   (sent_embeddings_2d[i, 0], sent_embeddings_2d[i, 1]),\n",
    "                   fontsize=7, alpha=0.7,\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white',\n",
    "                            edgecolor='gray', alpha=0.7))\n",
    "\n",
    "    plt.colorbar(scatter, label='Sentence Position in Video')\n",
    "    plt.xlabel('t-SNE Dimension 1', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('t-SNE Dimension 2', fontsize=12, fontweight='bold')\n",
    "    plt.title('Sentence Embeddings Visualization (Sentence-BERT + t-SNE)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/sentence_embeddings_tsne.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úì Saved: sentence_embeddings_tsne.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 19: COMPARATIVE ANALYSIS ACROSS VIDEOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARATIVE ANALYSIS ACROSS ALL VIDEOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive comparison DataFrame\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Video ID': r['video_id'],\n",
    "        'Sentences': r['statistics']['num_sentences'],\n",
    "        'Tokens': r['statistics']['num_tokens'],\n",
    "        'Unique Tokens': r['statistics']['num_unique_tokens'],\n",
    "        'Lexical Diversity': r['statistics']['lexical_diversity'],\n",
    "        'Avg Word Length': r['statistics']['avg_word_length'],\n",
    "        'Avg Sent Length': r['statistics']['avg_sentence_length'],\n",
    "        'Named Entities': r['entities']['num_entities'],\n",
    "        'Nouns': r['pos_analysis']['num_nouns'],\n",
    "        'Verbs': r['pos_analysis']['num_verbs']\n",
    "    }\n",
    "    for r in analysis_results\n",
    "])\n",
    "\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(comparison_df.describe())\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(f\"{CONFIG['output_dir']}/video_comparison.csv\", index=False)\n",
    "print(f\"\\n‚úì Saved: video_comparison.csv\")\n",
    "\n",
    "# Comparative visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Token counts comparison\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(range(len(comparison_df)), comparison_df['Tokens'],\n",
    "       color='steelblue', edgecolor='navy', linewidth=1.5)\n",
    "ax1.set_xticks(range(len(comparison_df)))\n",
    "ax1.set_xticklabels(comparison_df['Video ID'], rotation=45, ha='right')\n",
    "ax1.set_ylabel('Token Count', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Token Count per Video', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Lexical diversity comparison\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(range(len(comparison_df)), comparison_df['Lexical Diversity'],\n",
    "       color='coral', edgecolor='darkred', linewidth=1.5)\n",
    "ax2.set_xticks(range(len(comparison_df)))\n",
    "ax2.set_xticklabels(comparison_df['Video ID'], rotation=45, ha='right')\n",
    "ax2.set_ylabel('Lexical Diversity', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Lexical Diversity per Video', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Named entities comparison\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(range(len(comparison_df)), comparison_df['Named Entities'],\n",
    "       color='teal', edgecolor='darkslategray', linewidth=1.5)\n",
    "ax3.set_xticks(range(len(comparison_df)))\n",
    "ax3.set_xticklabels(comparison_df['Video ID'], rotation=45, ha='right')\n",
    "ax3.set_ylabel('Entity Count', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Named Entities per Video', fontsize=12, fontweight='bold')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. POS distribution comparison (Nouns vs Verbs)\n",
    "ax4 = axes[1, 1]\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, comparison_df['Nouns'], width, label='Nouns',\n",
    "       color='#95E1D3', edgecolor='black', linewidth=1)\n",
    "ax4.bar(x + width/2, comparison_df['Verbs'], width, label='Verbs',\n",
    "       color='#FFD3B6', edgecolor='black', linewidth=1)\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(comparison_df['Video ID'], rotation=45, ha='right')\n",
    "ax4.set_ylabel('Count', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Nouns vs Verbs per Video', fontsize=12, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Comparative Analysis Across Videos', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/comparative_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Saved: comparative_analysis.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 20: FINAL SUMMARY & EXPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY & REPORT GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate comprehensive summary\n",
    "final_summary = {\n",
    "    'project_info': {\n",
    "        'phase': 'Phase 1 - Data Preprocessing and Visualization',\n",
    "        'videos_processed': len(transcripts_data),\n",
    "        'total_words': sum(d['word_count'] for d in transcripts_data),\n",
    "        'total_duration_minutes': sum(d['duration_seconds'] for d in transcripts_data) / 60\n",
    "    },\n",
    "    'preprocessing_summary': {\n",
    "        'total_tokens_after_processing': sum(d['word_count'] for d in processed_data),\n",
    "        'unique_vocabulary': len(set(word for d in processed_data for word in d['lemmatized'])),\n",
    "        'average_lexical_diversity': np.mean([d['lexical_diversity'] for d in processed_data])\n",
    "    },\n",
    "    'embeddings_generated': {\n",
    "        'tfidf_dimensions': tfidf_matrix.shape,\n",
    "        'word2vec_vocabulary': len(w2v_model.wv),\n",
    "        'word2vec_dimensions': w2v_model.vector_size,\n",
    "        'sentence_embeddings_count': len(sentence_embeddings),\n",
    "        'sentence_embedding_dimensions': sentence_embeddings.shape[1]\n",
    "    },\n",
    "    'visualizations_created': [\n",
    "        'word_frequency.png',\n",
    "        'wordcloud.png',\n",
    "        'text_statistics.png',\n",
    "        'pos_distribution.png',\n",
    "        'entity_distribution.png',\n",
    "        'embeddings_pca.png',\n",
    "        'embeddings_tsne.png',\n",
    "        'similarity_heatmap.png',\n",
    "        'sentence_embeddings_tsne.png',\n",
    "        'comparative_analysis.png'\n",
    "    ],\n",
    "    'key_findings': {\n",
    "        'most_common_words': [word for word, _ in first_video['statistics']['most_common_words'][:10]],\n",
    "        'average_sentence_length': np.mean([r['statistics']['avg_sentence_length'] for r in analysis_results]),\n",
    "        'total_named_entities': sum(r['entities']['num_entities'] for r in analysis_results)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save final summary\n",
    "with open(f\"{CONFIG['output_dir']}/phase1_final_summary.json\", 'w') as f:\n",
    "    json.dump(final_summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\nPhase 1 Summary:\")\n",
    "print(json.dumps(final_summary, indent=2, default=str))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì PHASE 1 COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nDeliverables:\")\n",
    "print(f\"  1. Processed Transcripts: {CONFIG['output_dir']}/processed_transcripts.json\")\n",
    "print(f\"  2. Analysis Results: {CONFIG['output_dir']}/analysis_results.json\")\n",
    "print(f\"  3. Word2Vec Model: {CONFIG['output_dir']}/word2vec.model\")\n",
    "print(f\"  4. Sentence Embeddings: {CONFIG['output_dir']}/sentence_embeddings.npy\")\n",
    "print(f\"  5. Visualizations: {CONFIG['output_dir']}/*.png (10 files)\")\n",
    "print(f\"  6. Comparison Data: {CONFIG['output_dir']}/video_comparison.csv\")\n",
    "print(f\"  7. Final Summary: {CONFIG['output_dir']}/phase1_final_summary.json\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  ‚Üí Prepare Phase 1 Report (max 2 pages)\")\n",
    "print(\"  ‚Üí Include key visualizations in report\")\n",
    "print(\"  ‚Üí Document preprocessing decisions and observations\")\n",
    "print(\"  ‚Üí Proceed to Phase 2: Model Selection & Training\")\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 21: EXPORT FOR PHASE 2\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPARING DATA FOR PHASE 2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Package data for Phase 2\n",
    "phase2_data = {\n",
    "    'processed_texts': [d['processed_text'] for d in processed_data],\n",
    "    'lemmatized_tokens': [d['lemmatized'] for d in processed_data],\n",
    "    'video_ids': [d['video_id'] for d in processed_data],\n",
    "    'tfidf_matrix': tfidf_matrix.toarray().tolist(),  # Convert sparse to dense\n",
    "    'tfidf_features': feature_names.tolist(),\n",
    "    'word2vec_model_path': f\"{CONFIG['output_dir']}/word2vec.model\",\n",
    "    'sentence_embeddings_path': f\"{CONFIG['output_dir']}/sentence_embeddings.npy\"\n",
    "}\n",
    "\n",
    "# Save for Phase 2\n",
    "with open(f\"{CONFIG['output_dir']}/phase2_input_data.json\", 'w') as f:\n",
    "    json.dump(phase2_data, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Phase 2 input data prepared: {CONFIG['output_dir']}/phase2_input_data.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL TASKS COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPB7lVITRahSbRSFhvUKx0T",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
